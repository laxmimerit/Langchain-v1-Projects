{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1dfc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BUILDING A SEMANTIC SEARCH ENGINE WITH LANGCHAIN\n",
      "================================================================================\n",
      "\n",
      "OVERVIEW (from LangChain docs):\n",
      "This tutorial demonstrates LangChain's document loader, embedding, and vector store \n",
      "abstractions. These are designed to support retrieval of data from databases and \n",
      "other sources for integration with LLM workflows, particularly for RAG applications.\n",
      "\n",
      "\n",
      "============================================================\n",
      "STEP 1: DOCUMENTS AND DOCUMENT LOADERS\n",
      "============================================================\n",
      "\n",
      "WHAT IS A DOCUMENT? (LangChain Documentation):\n",
      "LangChain implements a Document abstraction with three attributes:\n",
      "- page_content: a string representing the content\n",
      "- metadata: a dict containing arbitrary metadata  \n",
      "- id: (optional) a string identifier for the document\n",
      "\n",
      "The metadata attribute can capture information about the source of the document,\n",
      "its relationship to other documents, and other information. Note that an individual \n",
      "Document object often represents a chunk of a larger document.\n",
      "\n",
      "\n",
      "1.1 Loading PDF Document...\n",
      "Using PyPDFLoader which loads one Document object per PDF page.\n",
      "For each page, we can access:\n",
      "- The string content of the page\n",
      "- Metadata containing the file name and page number\n",
      "\n",
      "✓ Loaded 174 pages from PDF\n",
      "✓ Each page is now a Document object with content and metadata\n",
      "\n",
      "Sample Document Structure:\n",
      "- Content length: 2140 characters\n",
      "- Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-11T01:48:37+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-11T01:48:37+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'https://arxiv.org/pdf/2501.04040.pdf', 'total_pages': 174, 'page': 0, 'page_label': '1'}\n",
      "- Content preview: A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "Riccardo Torlone\n",
      "Roma Tre University\n",
      "Italy\n",
      "riccard...\n",
      "\n",
      "============================================================\n",
      "STEP 2: TEXT SPLITTING\n",
      "============================================================\n",
      "\n",
      "WHY SPLIT TEXT? (LangChain Documentation):\n",
      "For both information retrieval and downstream question-answering purposes, \n",
      "a page may be too coarse a representation. Our goal is to retrieve Document \n",
      "objects that answer an input query, and further splitting our PDF helps ensure \n",
      "that the meanings of relevant portions are not \"washed out\" by surrounding text.\n",
      "\n",
      "RECURSIVE CHARACTER TEXT SPLITTER:\n",
      "We use RecursiveCharacterTextSplitter, which recursively splits the document \n",
      "using common separators like new lines until each chunk is the appropriate size. \n",
      "This is the recommended text splitter for generic text use cases.\n",
      "\n",
      "OVERLAP STRATEGY:\n",
      "The overlap helps mitigate the possibility of separating a statement from \n",
      "important context related to it.\n",
      "\n",
      "\n",
      "2.1 Configuring Text Splitter...\n",
      "- Chunk size: 4096 characters (as specified)\n",
      "- Overlap: 410 characters (10% overlap)\n",
      "- Method: Recursive character splitting\n",
      "\n",
      "2.2 Splitting documents into chunks...\n",
      "\n",
      "✓ Split 174 pages into 183 chunks\n",
      "✓ Each chunk contains ~4096 characters with 410-character overlap\n",
      "✓ Start index preserved in metadata for tracking\n",
      "\n",
      "Chunk Analysis:\n",
      "- Average chunk size: 2623 characters\n",
      "- Largest chunk: 4079 characters\n",
      "- Smallest chunk: 420 characters\n",
      "\n",
      "============================================================\n",
      "STEP 3: EMBEDDINGS\n",
      "============================================================\n",
      "\n",
      "WHAT ARE EMBEDDINGS? (LangChain Documentation):\n",
      "Vector search is a common way to store and search over unstructured data. \n",
      "The idea is to store numeric vectors that are associated with the text. \n",
      "Given a query, we can embed it as a vector of the same dimension and use \n",
      "vector similarity metrics (such as cosine similarity) to identify related text.\n",
      "\n",
      "HOW EMBEDDINGS WORK:\n",
      "Embeddings typically represent text as a \"dense\" vector such that texts with \n",
      "similar meanings are geometrically close. This lets us retrieve relevant \n",
      "information just by passing in a question, without knowledge of any specific \n",
      "key-terms used in the document.\n",
      "\n",
      "\n",
      "3.1 Setting up Ollama Embeddings...\n",
      "Using nomic-embed-text model for local embedding generation\n",
      "✓ Embedding model configured\n",
      "✓ Text will be converted to numeric vectors for similarity search\n",
      "\n",
      "============================================================\n",
      "STEP 4: VECTOR STORES\n",
      "============================================================\n",
      "\n",
      "WHAT ARE VECTOR STORES? (LangChain Documentation):\n",
      "LangChain VectorStore objects contain methods for adding text and Document \n",
      "objects to the store, and querying them using various similarity metrics. \n",
      "They are often initialized with embedding models, which determine how text \n",
      "data is translated to numeric vectors.\n",
      "\n",
      "CHROMA VECTOR STORE:\n",
      "We're using Chroma, which can run in-memory for lightweight workloads or \n",
      "with persistence for production use. Some vector stores are hosted by \n",
      "providers and require credentials; others like Chroma can run locally.\n",
      "\n",
      "\n",
      "4.1 Creating Chroma Vector Store...\n",
      "- Collection name: pdf_collection\n",
      "- Storage: Local persistent directory\n",
      "- Embedding function: nomic-embed-text via Ollama\n",
      "✓ Chroma vector store created with local persistence\n",
      "\n",
      "4.2 Adding documents to vector store...\n",
      "Converting text chunks to embeddings and storing in vector database...\n",
      "✓ Added 183 document chunks to vector store\n",
      "✓ Each chunk has been converted to a vector and stored\n",
      "\n",
      "============================================================\n",
      "STEP 5: QUERYING THE VECTOR STORE\n",
      "============================================================\n",
      "\n",
      "VECTOR STORE QUERYING (LangChain Documentation):\n",
      "Once we've instantiated a VectorStore that contains documents, we can query it.\n",
      "VectorStore includes methods for querying:\n",
      "- Synchronously and asynchronously\n",
      "- By string query and by vector  \n",
      "- With and without returning similarity scores\n",
      "- By similarity and maximum marginal relevance (MMR)\n",
      "\n",
      "\n",
      "5.1 Basic Similarity Search\n",
      "Finding documents most similar to a query using cosine similarity...\n",
      "\n",
      "Query: 'What is the main topic and methodology of this research?'\n",
      "Retrieved 3 most similar chunks:\n",
      "\n",
      "--- Result 1 ---\n",
      "Content: Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence of LLMs, research on RAG initially focused\n",
      "on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the in-\n",
      "ference...\n",
      "Source: Page 118\n",
      "\n",
      "--- Result 2 ---\n",
      "Content: Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence of LLMs, research on RAG initially focused\n",
      "on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the in-\n",
      "ference...\n",
      "Source: Page 118\n",
      "\n",
      "--- Result 3 ---\n",
      "Content: Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence of LLMs, research on RAG initially focused\n",
      "on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the in-\n",
      "ference...\n",
      "Source: Page 118\n",
      "\n",
      "5.2 Similarity Search with Scores\n",
      "Same search but with similarity scores to see confidence levels...\n",
      "\n",
      "--- Result 1 (Similarity Score: 0.9371) ---\n",
      "Content: Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence of LLMs, research on RAG initially focused\n",
      "on lever...\n",
      "Source: Page 118\n",
      "\n",
      "--- Result 2 (Similarity Score: 0.9371) ---\n",
      "Content: Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence of LLMs, research on RAG initially focused\n",
      "on lever...\n",
      "Source: Page 118\n",
      "\n",
      "5.3 Metadata Filtering\n",
      "Using metadata filters to search specific parts of the document...\n",
      "\n",
      "Available metadata in our chunks:\n",
      "Sample metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-11T01:48:37+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-11T01:48:37+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'https://arxiv.org/pdf/2501.04040.pdf', 'total_pages': 174, 'page': 0, 'page_label': '1', 'start_index': 0}\n",
      "Available page numbers (sample): [0, 1, 2, 3, 4]...\n",
      "\n",
      "5.3.1 Filter by Specific Page\n",
      "Searching only in Page 0:\n",
      "  Result 1: Page 0 - A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "...\n",
      "  Result 2: Page 0 - A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "...\n",
      "\n",
      "5.3.2 Filter by Page Range\n",
      "Searching in pages >= 1:\n",
      "  Result 1: Page 90 - Figure 40: A: Chain of thoughts (in blue) are intermediate reasoning steps towards a final answer.\n",
      "The input of CoT prompting is a stack of a few (oft...\n",
      "  Result 2: Page 90 - Figure 40: A: Chain of thoughts (in blue) are intermediate reasoning steps towards a final answer.\n",
      "The input of CoT prompting is a stack of a few (oft...\n",
      "  Result 3: Page 90 - Figure 40: A: Chain of thoughts (in blue) are intermediate reasoning steps towards a final answer.\n",
      "The input of CoT prompting is a stack of a few (oft...\n",
      "\n",
      "5.3.3 Multiple Metadata Filters\n",
      "Using complex filter (page >= 0 AND has source):\n",
      "  Result 1: Page 118 - Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence o...\n",
      "  Result 2: Page 118 - Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence o...\n",
      "\n",
      "5.4 Search by Vector with Filtering\n",
      "Combining vector search with metadata filtering...\n",
      "Vector search in Page 0:\n",
      "  Result 1: A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "...\n",
      "  Result 2: A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "...\n",
      "\n",
      "============================================================\n",
      "STEP 6: RETRIEVERS\n",
      "============================================================\n",
      "\n",
      "WHAT ARE RETRIEVERS? (LangChain Documentation):\n",
      "LangChain Retrievers are Runnables that implement a standard set of methods \n",
      "(e.g., synchronous and asynchronous invoke and batch operations). Although \n",
      "we can construct retrievers from vector stores, retrievers can interface \n",
      "with non-vector store sources of data as well (such as external APIs).\n",
      "\n",
      "RETRIEVER TYPES:\n",
      "VectorStoreRetriever supports search types:\n",
      "- \"similarity\" (default): Returns most similar documents\n",
      "- \"mmr\" (maximum marginal relevance): Balances similarity with diversity  \n",
      "- \"similarity_score_threshold\": Filters by minimum similarity score\n",
      "\n",
      "\n",
      "6.1 Creating Different Types of Retrievers...\n",
      "MMR balances similarity with diversity in retrieved results\n",
      "Score threshold retriever only returns documents above similarity threshold\n",
      "\n",
      "6.2 Retrievers with Metadata Filtering...\n",
      "Available pages for filtering: [0, 1, 2, 3, 4]...\n",
      "\n",
      "6.2.1 Similarity Retriever with Page Filter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered search (Page 0) found 3 documents\n",
      "  Result 1: Page 0 - A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "...\n",
      "  Result 2: Page 0 - A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "...\n",
      "  Result 3: Page 0 - A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "...\n",
      "\n",
      "6.2.2 MMR Retriever with Page Range Filter\n",
      "MMR search (Pages >= 1) found 3 diverse documents\n",
      "  Result 1: Page 86 - probability for a hypothesis as more evidence or information becomes available. Fundamentally, Bayesian\n",
      "inference uses prior knowledge, in the form of...\n",
      "  Result 2: Page 90 - Figure 40: A: Chain of thoughts (in blue) are intermediate reasoning steps towards a final answer.\n",
      "The input of CoT prompting is a stack of a few (oft...\n",
      "  Result 3: Page 111 - Figure 57: Reflexion works on decision-making, programming, and reasoning tasks. Source: Shinn\n",
      "et al. [322]\n",
      "Figure 58: (a) Diagram of Reflexion. (b) R...\n",
      "\n",
      "6.3 Advanced Filter Examples...\n",
      "\n",
      "6.3.1 Complex AND/OR Filtering\n",
      "Complex filter search found 2 documents\n",
      "\n",
      "6.3.2 Custom Metadata-Based Retrieval\n",
      "By Source: Found 2 documents\n",
      "First Few Pages: Found 2 documents\n",
      "Later Pages: Found 2 documents\n",
      "\n",
      "6.4 Testing All Retriever Types...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Similarity Retriever: Found 4 documents\n",
      "  First result: Page 86 - probability for a hypothesis as more evidence or information becomes available. Fundamentally, Bayes...\n",
      "\n",
      "MMR (Diversity) Retriever: Found 3 documents\n",
      "  First result: Page 86 - probability for a hypothesis as more evidence or information becomes available. Fundamentally, Bayes...\n",
      "\n",
      "Score Threshold Retriever: Found 0 documents\n",
      "\n",
      "============================================================\n",
      "STEP 7: RAG APPLICATION FOUNDATION\n",
      "============================================================\n",
      "\n",
      "RAG APPLICATIONS (LangChain Documentation):\n",
      "Retrievers can easily be incorporated into more complex applications, such as \n",
      "retrieval-augmented generation (RAG) applications that combine a given question \n",
      "with retrieved context into a prompt for a LLM.\n",
      "\n",
      "WHAT WE'VE BUILT:\n",
      "We now have a complete semantic search engine that can:\n",
      "1. Load and process PDF documents\n",
      "2. Split them into meaningful chunks  \n",
      "3. Convert chunks to vector embeddings\n",
      "4. Store vectors in a searchable database\n",
      "5. Retrieve relevant passages for any query\n",
      "6. Support different retrieval strategies (similarity, MMR)\n",
      "\n",
      "\n",
      "7.1 Testing Complete Pipeline...\n",
      "\n",
      "Query: 'What are the key contributions of this paper?'\n",
      "✓ Retrieved 4 relevant document chunks\n",
      "✓ These chunks could now be sent to an LLM for answer generation\n",
      "\n",
      "Context that would be sent to LLM:\n",
      "\n",
      "Chunk 1: Figure 56: Overview of the DEPS interactive plannet architecture. Source: Wang et al. [344]\n",
      "as an explainer to locate the errors in the previous plan. Finally, a planner will refine the plan\n",
      "using the descriptor and explainer information. To improve ...\n",
      "\n",
      "Chunk 2: Figure 56: Overview of the DEPS interactive plannet architecture. Source: Wang et al. [344]\n",
      "as an explainer to locate the errors in the previous plan. Finally, a planner will refine the plan\n",
      "using the descriptor and explainer information. To improve ...\n",
      "\n",
      "================================================================================\n",
      "TUTORIAL COMPLETE - SEMANTIC SEARCH ENGINE BUILT!\n",
      "================================================================================\n",
      "\n",
      "WHAT WE ACCOMPLISHED:\n",
      "✓ Loaded PDF document using PyPDFLoader (174 pages)\n",
      "✓ Split into 183 chunks using RecursiveCharacterTextSplitter\n",
      "✓ Generated embeddings using nomic-embed-text model\n",
      "✓ Created persistent Chroma vector store\n",
      "✓ Implemented similarity and MMR retrieval strategies  \n",
      "✓ Built foundation for RAG applications\n",
      "\n",
      "DATA PERSISTENCE:\n",
      "✓ Vector store saved to: ./chroma_db\n",
      "✓ Can be reloaded anytime with the same configuration\n",
      "✓ Ready for production RAG applications\n",
      "\n",
      "NEXT STEPS:\n",
      "- Connect to an LLM (like Ollama) to generate answers\n",
      "- Implement conversation memory for chat applications  \n",
      "- Add metadata filtering for more precise retrieval\n",
      "- Scale to multiple documents and collections\n",
      "\n",
      "\n",
      "This semantic search engine is now ready to power RAG applications!\n"
     ]
    }
   ],
   "source": [
    "# LangChain Knowledge Base Tutorial: Building a Semantic Search Engine\n",
    "# Based on official documentation: https://docs.langchain.com/oss/python/langchain/knowledge-base\n",
    "\n",
    "\"\"\"\n",
    "WHAT WE'RE BUILDING:\n",
    "According to LangChain documentation, we'll build a search engine over a PDF document \n",
    "that allows us to retrieve passages similar to an input query. This is the foundation \n",
    "for Retrieval-Augmented Generation (RAG) applications.\n",
    "\n",
    "CORE CONCEPTS COVERED:\n",
    "1. Documents and document loaders\n",
    "2. Text splitters  \n",
    "3. Embeddings\n",
    "4. Vector stores and retrievers\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Required packages:\n",
    "# pip install -qU langchain-chroma langchain-ollama langchain-community pypdf\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BUILDING A SEMANTIC SEARCH ENGINE WITH LANGCHAIN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "OVERVIEW (from LangChain docs):\n",
    "This tutorial demonstrates LangChain's document loader, embedding, and vector store \n",
    "abstractions. These are designed to support retrieval of data from databases and \n",
    "other sources for integration with LLM workflows, particularly for RAG applications.\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: DOCUMENTS AND DOCUMENT LOADERS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 1: DOCUMENTS AND DOCUMENT LOADERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "WHAT IS A DOCUMENT? (LangChain Documentation):\n",
    "LangChain implements a Document abstraction with three attributes:\n",
    "- page_content: a string representing the content\n",
    "- metadata: a dict containing arbitrary metadata  \n",
    "- id: (optional) a string identifier for the document\n",
    "\n",
    "The metadata attribute can capture information about the source of the document,\n",
    "its relationship to other documents, and other information. Note that an individual \n",
    "Document object often represents a chunk of a larger document.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n1.1 Loading PDF Document...\")\n",
    "print(\"Using PyPDFLoader which loads one Document object per PDF page.\")\n",
    "print(\"For each page, we can access:\")\n",
    "print(\"- The string content of the page\")\n",
    "print(\"- Metadata containing the file name and page number\")\n",
    "\n",
    "# Load PDF - works with both online URLs and local file paths\n",
    "pdf_url = \"https://arxiv.org/pdf/2501.04040.pdf\"\n",
    "loader = PyPDFLoader(pdf_url)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(documents)} pages from PDF\")\n",
    "print(f\"✓ Each page is now a Document object with content and metadata\")\n",
    "\n",
    "# Show sample document structure\n",
    "if documents:\n",
    "    sample_doc = documents[0]\n",
    "    print(f\"\\nSample Document Structure:\")\n",
    "    print(f\"- Content length: {len(sample_doc.page_content)} characters\")\n",
    "    print(f\"- Metadata: {sample_doc.metadata}\")\n",
    "    print(f\"- Content preview: {sample_doc.page_content[:200]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: TEXT SPLITTING  \n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2: TEXT SPLITTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "WHY SPLIT TEXT? (LangChain Documentation):\n",
    "For both information retrieval and downstream question-answering purposes, \n",
    "a page may be too coarse a representation. Our goal is to retrieve Document \n",
    "objects that answer an input query, and further splitting our PDF helps ensure \n",
    "that the meanings of relevant portions are not \"washed out\" by surrounding text.\n",
    "\n",
    "RECURSIVE CHARACTER TEXT SPLITTER:\n",
    "We use RecursiveCharacterTextSplitter, which recursively splits the document \n",
    "using common separators like new lines until each chunk is the appropriate size. \n",
    "This is the recommended text splitter for generic text use cases.\n",
    "\n",
    "OVERLAP STRATEGY:\n",
    "The overlap helps mitigate the possibility of separating a statement from \n",
    "important context related to it.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n2.1 Configuring Text Splitter...\")\n",
    "print(\"- Chunk size: 4096 characters (as specified)\")\n",
    "print(\"- Overlap: 410 characters (10% overlap)\")\n",
    "print(\"- Method: Recursive character splitting\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4096,\n",
    "    chunk_overlap=410,  # 10% of 4096\n",
    "    length_function=len,\n",
    "    add_start_index=True,  # Preserves character index as metadata\n",
    ")\n",
    "\n",
    "print(\"\\n2.2 Splitting documents into chunks...\")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"\\n✓ Split {len(documents)} pages into {len(chunks)} chunks\")\n",
    "print(f\"✓ Each chunk contains ~4096 characters with 410-character overlap\")\n",
    "print(f\"✓ Start index preserved in metadata for tracking\")\n",
    "\n",
    "# Show chunk analysis\n",
    "if chunks:\n",
    "    chunk_sizes = [len(chunk.page_content) for chunk in chunks]\n",
    "    print(f\"\\nChunk Analysis:\")\n",
    "    print(f\"- Average chunk size: {sum(chunk_sizes) / len(chunk_sizes):.0f} characters\")\n",
    "    print(f\"- Largest chunk: {max(chunk_sizes)} characters\")\n",
    "    print(f\"- Smallest chunk: {min(chunk_sizes)} characters\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: EMBEDDINGS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 3: EMBEDDINGS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "WHAT ARE EMBEDDINGS? (LangChain Documentation):\n",
    "Vector search is a common way to store and search over unstructured data. \n",
    "The idea is to store numeric vectors that are associated with the text. \n",
    "Given a query, we can embed it as a vector of the same dimension and use \n",
    "vector similarity metrics (such as cosine similarity) to identify related text.\n",
    "\n",
    "HOW EMBEDDINGS WORK:\n",
    "Embeddings typically represent text as a \"dense\" vector such that texts with \n",
    "similar meanings are geometrically close. This lets us retrieve relevant \n",
    "information just by passing in a question, without knowledge of any specific \n",
    "key-terms used in the document.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n3.1 Setting up Ollama Embeddings...\")\n",
    "print(\"Using nomic-embed-text model for local embedding generation\")\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "print(\"✓ Embedding model configured\")\n",
    "print(\"✓ Text will be converted to numeric vectors for similarity search\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: VECTOR STORES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 4: VECTOR STORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "WHAT ARE VECTOR STORES? (LangChain Documentation):\n",
    "LangChain VectorStore objects contain methods for adding text and Document \n",
    "objects to the store, and querying them using various similarity metrics. \n",
    "They are often initialized with embedding models, which determine how text \n",
    "data is translated to numeric vectors.\n",
    "\n",
    "CHROMA VECTOR STORE:\n",
    "We're using Chroma, which can run in-memory for lightweight workloads or \n",
    "with persistence for production use. Some vector stores are hosted by \n",
    "providers and require credentials; others like Chroma can run locally.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n4.1 Creating Chroma Vector Store...\")\n",
    "print(\"- Collection name: pdf_collection\")\n",
    "print(\"- Storage: Local persistent directory\")\n",
    "print(\"- Embedding function: nomic-embed-text via Ollama\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"pdf_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "print(\"✓ Chroma vector store created with local persistence\")\n",
    "\n",
    "print(\"\\n4.2 Adding documents to vector store...\")\n",
    "print(\"Converting text chunks to embeddings and storing in vector database...\")\n",
    "\n",
    "vector_store.add_documents(documents=chunks)\n",
    "\n",
    "print(f\"✓ Added {len(chunks)} document chunks to vector store\")\n",
    "print(\"✓ Each chunk has been converted to a vector and stored\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: QUERYING THE VECTOR STORE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 5: QUERYING THE VECTOR STORE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "VECTOR STORE QUERYING (LangChain Documentation):\n",
    "Once we've instantiated a VectorStore that contains documents, we can query it.\n",
    "VectorStore includes methods for querying:\n",
    "- Synchronously and asynchronously\n",
    "- By string query and by vector  \n",
    "- With and without returning similarity scores\n",
    "- By similarity and maximum marginal relevance (MMR)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n5.1 Basic Similarity Search\")\n",
    "print(\"Finding documents most similar to a query using cosine similarity...\")\n",
    "\n",
    "query = \"What is the main topic and methodology of this research?\"\n",
    "results = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(f\"Retrieved {len(results)} most similar chunks:\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(f\"Content: {doc.page_content[:300]}...\")\n",
    "    print(f\"Source: Page {doc.metadata.get('page', 'unknown')}\")\n",
    "\n",
    "print(\"\\n5.2 Similarity Search with Scores\")\n",
    "print(\"Same search but with similarity scores to see confidence levels...\")\n",
    "\n",
    "results_with_scores = vector_store.similarity_search_with_score(query, k=2)\n",
    "\n",
    "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "    print(f\"\\n--- Result {i} (Similarity Score: {score:.4f}) ---\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "    print(f\"Source: Page {doc.metadata.get('page', 'unknown')}\")\n",
    "\n",
    "print(\"\\n5.3 Metadata Filtering\")\n",
    "print(\"Using metadata filters to search specific parts of the document...\")\n",
    "\n",
    "# First, let's see what metadata is available\n",
    "print(\"\\nAvailable metadata in our chunks:\")\n",
    "if chunks:\n",
    "    sample_metadata = chunks[0].metadata\n",
    "    print(f\"Sample metadata: {sample_metadata}\")\n",
    "    \n",
    "    # Get unique page numbers for filtering examples\n",
    "    page_numbers = set()\n",
    "    for chunk in chunks[:10]:  # Check first 10 chunks\n",
    "        if 'page' in chunk.metadata:\n",
    "            page_numbers.add(chunk.metadata['page'])\n",
    "    print(f\"Available page numbers (sample): {sorted(list(page_numbers))[:5]}...\")\n",
    "\n",
    "print(\"\\n5.3.1 Filter by Specific Page\")\n",
    "if page_numbers:\n",
    "    target_page = sorted(list(page_numbers))[0]  # Use first available page\n",
    "    page_results = vector_store.similarity_search(\n",
    "        \"methodology approach\",\n",
    "        k=2,\n",
    "        filter={\"page\": target_page}\n",
    "    )\n",
    "    print(f\"Searching only in Page {target_page}:\")\n",
    "    for i, doc in enumerate(page_results, 1):\n",
    "        print(f\"  Result {i}: Page {doc.metadata.get('page')} - {doc.page_content[:150]}...\")\n",
    "\n",
    "print(\"\\n5.3.2 Filter by Page Range\")\n",
    "if len(page_numbers) > 1:\n",
    "    # Filter for pages greater than or equal to a certain page\n",
    "    min_page = sorted(list(page_numbers))[1] if len(page_numbers) > 1 else sorted(list(page_numbers))[0]\n",
    "    range_results = vector_store.similarity_search(\n",
    "        \"results conclusions\",\n",
    "        k=3,\n",
    "        filter={\"page\": {\"$gte\": min_page}}  # Pages >= min_page\n",
    "    )\n",
    "    print(f\"Searching in pages >= {min_page}:\")\n",
    "    for i, doc in enumerate(range_results, 1):\n",
    "        print(f\"  Result {i}: Page {doc.metadata.get('page')} - {doc.page_content[:150]}...\")\n",
    "\n",
    "print(\"\\n5.3.3 Multiple Metadata Filters\")\n",
    "# Complex filtering with multiple conditions\n",
    "complex_results = vector_store.similarity_search(\n",
    "    \"research findings\",\n",
    "    k=2,\n",
    "    filter={\n",
    "        \"$and\": [\n",
    "            {\"page\": {\"$gte\": 0}},  # Page 0 or higher\n",
    "            {\"source\": {\"$ne\": \"\"}}  # Has a source\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(\"Using complex filter (page >= 0 AND has source):\")\n",
    "for i, doc in enumerate(complex_results, 1):\n",
    "    print(f\"  Result {i}: Page {doc.metadata.get('page')} - {doc.page_content[:150]}...\")\n",
    "\n",
    "print(\"\\n5.4 Search by Vector with Filtering\")\n",
    "print(\"Combining vector search with metadata filtering...\")\n",
    "\n",
    "# Generate embedding for a query and search with filter\n",
    "query_embedding = embeddings.embed_query(\"experimental setup\")\n",
    "if page_numbers:\n",
    "    target_page = sorted(list(page_numbers))[0]\n",
    "    vector_results = vector_store.similarity_search_by_vector(\n",
    "        embedding=query_embedding,\n",
    "        k=2,\n",
    "        filter={\"page\": target_page}\n",
    "    )\n",
    "    print(f\"Vector search in Page {target_page}:\")\n",
    "    for i, doc in enumerate(vector_results, 1):\n",
    "        print(f\"  Result {i}: {doc.page_content[:150]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: RETRIEVERS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 6: RETRIEVERS\") \n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "WHAT ARE RETRIEVERS? (LangChain Documentation):\n",
    "LangChain Retrievers are Runnables that implement a standard set of methods \n",
    "(e.g., synchronous and asynchronous invoke and batch operations). Although \n",
    "we can construct retrievers from vector stores, retrievers can interface \n",
    "with non-vector store sources of data as well (such as external APIs).\n",
    "\n",
    "RETRIEVER TYPES:\n",
    "VectorStoreRetriever supports search types:\n",
    "- \"similarity\" (default): Returns most similar documents\n",
    "- \"mmr\" (maximum marginal relevance): Balances similarity with diversity  \n",
    "- \"similarity_score_threshold\": Filters by minimum similarity score\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n6.1 Creating Different Types of Retrievers...\")\n",
    "\n",
    "# Similarity Retriever\n",
    "similarity_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")\n",
    "\n",
    "# MMR Retriever\n",
    "print(\"MMR balances similarity with diversity in retrieved results\")\n",
    "mmr_retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", \n",
    "    search_kwargs={\"k\": 3, \"fetch_k\": 10, \"lambda_mult\": 0.5}\n",
    ")\n",
    "\n",
    "# Score Threshold Retriever\n",
    "print(\"Score threshold retriever only returns documents above similarity threshold\")\n",
    "threshold_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.5, \"k\": 5}\n",
    ")\n",
    "\n",
    "print(\"\\n6.2 Retrievers with Metadata Filtering...\")\n",
    "\n",
    "# Get available page numbers for filtering\n",
    "available_pages = set()\n",
    "for chunk in chunks[:20]:  # Check sample of chunks\n",
    "    if 'page' in chunk.metadata:\n",
    "        available_pages.add(chunk.metadata['page'])\n",
    "\n",
    "print(f\"Available pages for filtering: {sorted(list(available_pages))[:5]}...\")\n",
    "\n",
    "print(\"\\n6.2.1 Similarity Retriever with Page Filter\")\n",
    "if available_pages:\n",
    "    target_page = sorted(list(available_pages))[0]\n",
    "    filtered_similarity_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            \"filter\": {\"page\": target_page}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    test_query = \"research methodology\"\n",
    "    filtered_results = filtered_similarity_retriever.invoke(test_query)\n",
    "    print(f\"Filtered search (Page {target_page}) found {len(filtered_results)} documents\")\n",
    "    for i, doc in enumerate(filtered_results, 1):\n",
    "        print(f\"  Result {i}: Page {doc.metadata.get('page')} - {doc.page_content[:150]}...\")\n",
    "\n",
    "print(\"\\n6.2.2 MMR Retriever with Page Range Filter\")\n",
    "if len(available_pages) > 1:\n",
    "    min_page = sorted(list(available_pages))[1] if len(available_pages) > 1 else sorted(list(available_pages))[0]\n",
    "    filtered_mmr_retriever = vector_store.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            \"fetch_k\": 8,\n",
    "            \"lambda_mult\": 0.7,\n",
    "            \"filter\": {\"page\": {\"$gte\": min_page}}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    mmr_results = filtered_mmr_retriever.invoke(\"findings conclusions\")\n",
    "    print(f\"MMR search (Pages >= {min_page}) found {len(mmr_results)} diverse documents\")\n",
    "    for i, doc in enumerate(mmr_results, 1):\n",
    "        print(f\"  Result {i}: Page {doc.metadata.get('page')} - {doc.page_content[:150]}...\")\n",
    "\n",
    "print(\"\\n6.3 Advanced Filter Examples...\")\n",
    "\n",
    "print(\"\\n6.3.1 Complex AND/OR Filtering\")\n",
    "# Example of complex filtering (if supported by Chroma version)\n",
    "try:\n",
    "    complex_filter_retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": 2,\n",
    "            \"filter\": {\n",
    "                \"$and\": [\n",
    "                    {\"page\": {\"$gte\": 0}},\n",
    "                    {\"source\": {\"$ne\": \"\"}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    complex_results = complex_filter_retriever.invoke(\"experimental design\")\n",
    "    print(f\"Complex filter search found {len(complex_results)} documents\")\n",
    "except Exception as e:\n",
    "    print(f\"Complex filtering not fully supported in this Chroma version: {str(e)}\")\n",
    "\n",
    "print(\"\\n6.3.2 Custom Metadata-Based Retrieval\")\n",
    "# Show how to filter by different metadata fields\n",
    "metadata_examples = [\n",
    "    {\"filter_name\": \"By Source\", \"filter\": {\"source\": pdf_url}},\n",
    "    {\"filter_name\": \"First Few Pages\", \"filter\": {\"page\": {\"$lt\": 3}}},\n",
    "    {\"filter_name\": \"Later Pages\", \"filter\": {\"page\": {\"$gte\": 3}}},\n",
    "]\n",
    "\n",
    "for example in metadata_examples:\n",
    "    try:\n",
    "        custom_retriever = vector_store.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\n",
    "                \"k\": 2,\n",
    "                \"filter\": example[\"filter\"]\n",
    "            }\n",
    "        )\n",
    "        custom_results = custom_retriever.invoke(\"data analysis\")\n",
    "        print(f\"{example['filter_name']}: Found {len(custom_results)} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"{example['filter_name']}: Filter not supported - {str(e)}\")\n",
    "\n",
    "print(\"\\n6.4 Testing All Retriever Types...\")\n",
    "test_query = \"research findings and conclusions\"\n",
    "\n",
    "# Test all retrievers\n",
    "retrievers_to_test = [\n",
    "    (\"Basic Similarity\", similarity_retriever),\n",
    "    (\"MMR (Diversity)\", mmr_retriever),\n",
    "]\n",
    "\n",
    "# Add threshold retriever if it works\n",
    "try:\n",
    "    threshold_results = threshold_retriever.invoke(test_query)\n",
    "    retrievers_to_test.append((\"Score Threshold\", threshold_retriever))\n",
    "except Exception as e:\n",
    "    print(f\"Score threshold retriever not fully supported: {str(e)}\")\n",
    "\n",
    "for name, retriever in retrievers_to_test:\n",
    "    try:\n",
    "        results = retriever.invoke(test_query)\n",
    "        print(f\"\\n{name} Retriever: Found {len(results)} documents\")\n",
    "        if results:\n",
    "            print(f\"  First result: Page {results[0].metadata.get('page')} - {results[0].page_content[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name} Retriever error: {str(e)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: RAG FOUNDATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 7: RAG APPLICATION FOUNDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "RAG APPLICATIONS (LangChain Documentation):\n",
    "Retrievers can easily be incorporated into more complex applications, such as \n",
    "retrieval-augmented generation (RAG) applications that combine a given question \n",
    "with retrieved context into a prompt for a LLM.\n",
    "\n",
    "WHAT WE'VE BUILT:\n",
    "We now have a complete semantic search engine that can:\n",
    "1. Load and process PDF documents\n",
    "2. Split them into meaningful chunks  \n",
    "3. Convert chunks to vector embeddings\n",
    "4. Store vectors in a searchable database\n",
    "5. Retrieve relevant passages for any query\n",
    "6. Support different retrieval strategies (similarity, MMR)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n7.1 Testing Complete Pipeline...\")\n",
    "final_query = \"What are the key contributions of this paper?\"\n",
    "context_docs = similarity_retriever.invoke(final_query)\n",
    "\n",
    "print(f\"\\nQuery: '{final_query}'\")\n",
    "print(f\"✓ Retrieved {len(context_docs)} relevant document chunks\")\n",
    "print(\"✓ These chunks could now be sent to an LLM for answer generation\")\n",
    "\n",
    "# Show what would be sent to LLM\n",
    "print(f\"\\nContext that would be sent to LLM:\")\n",
    "for i, doc in enumerate(context_docs[:2], 1):  # Show first 2 for brevity\n",
    "    print(f\"\\nChunk {i}: {doc.page_content[:250]}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY AND PERSISTENCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TUTORIAL COMPLETE - SEMANTIC SEARCH ENGINE BUILT!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "WHAT WE ACCOMPLISHED:\n",
    "✓ Loaded PDF document using PyPDFLoader ({len(documents)} pages)\n",
    "✓ Split into {len(chunks)} chunks using RecursiveCharacterTextSplitter\n",
    "✓ Generated embeddings using nomic-embed-text model\n",
    "✓ Created persistent Chroma vector store\n",
    "✓ Implemented similarity and MMR retrieval strategies  \n",
    "✓ Built foundation for RAG applications\n",
    "\n",
    "DATA PERSISTENCE:\n",
    "✓ Vector store saved to: ./chroma_db\n",
    "✓ Can be reloaded anytime with the same configuration\n",
    "✓ Ready for production RAG applications\n",
    "\n",
    "NEXT STEPS:\n",
    "- Connect to an LLM (like Ollama) to generate answers\n",
    "- Implement conversation memory for chat applications  \n",
    "- Add metadata filtering for more precise retrieval\n",
    "- Scale to multiple documents and collections\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nThis semantic search engine is now ready to power RAG applications!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
