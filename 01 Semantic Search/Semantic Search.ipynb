{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45f918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages:\n",
    "# pip install -U langchain langgraph langchain-chroma langchain-ollama langchain-community pypdf\n",
    "\n",
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b82994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: DOCUMENTS AND DOCUMENT LOADERS\n",
    "# ============================================================================\n",
    "# Load PDF - works with both online URLs and local file paths\n",
    "pdf_url = \"https://arxiv.org/pdf/2501.04040.pdf\"\n",
    "loader = PyPDFLoader(pdf_url)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd952196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded 174 pages from PDF\n"
     ]
    }
   ],
   "source": [
    "documents[0]\n",
    "print(f\"\\n✓ Loaded {len(documents)} pages from PDF\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d522b35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Document Structure:\n",
      "- Content length: 2140 characters\n",
      "- Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-11T01:48:37+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-11T01:48:37+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'https://arxiv.org/pdf/2501.04040.pdf', 'total_pages': 174, 'page': 0, 'page_label': '1'}\n",
      "- Content preview: A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "Riccardo Torlone\n",
      "Roma Tre University\n",
      "Italy\n",
      "riccard...\n"
     ]
    }
   ],
   "source": [
    "sample_doc = documents[0]\n",
    "print(f\"\\nSample Document Structure:\")\n",
    "print(f\"- Content length: {len(sample_doc.page_content)} characters\")\n",
    "print(f\"- Metadata: {sample_doc.metadata}\")\n",
    "print(f\"- Content preview: {sample_doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc2c1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.1 Configuring Text Splitter...\n",
      "- Chunk size: 1024 characters (as specified)\n",
      "- Overlap: 100 characters (10% overlap)\n",
      "- Method: Recursive character splitting\n",
      "\n",
      "2.2 Splitting documents into chunks...\n",
      "\n",
      "✓ Split 174 pages into 593 chunks\n",
      "\n",
      "Chunk Analysis:\n",
      "- Average chunk size: 858 characters\n",
      "- Largest chunk: 1024 characters\n",
      "- Smallest chunk: 25 characters\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: TEXT SPLITTING  \n",
    "# ============================================================================\n",
    "print(\"\\n2.1 Configuring Text Splitter...\")\n",
    "print(\"- Chunk size: 1024 characters (as specified)\")\n",
    "print(\"- Overlap: 100 characters (10% overlap)\")\n",
    "print(\"- Method: Recursive character splitting\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=100,  # 10% of 1024\n",
    "    length_function=len,\n",
    "    add_start_index=True,  # Preserves character index as metadata\n",
    ")\n",
    "\n",
    "print(\"\\n2.2 Splitting documents into chunks...\")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"\\n✓ Split {len(documents)} pages into {len(chunks)} chunks\")\n",
    "\n",
    "chunk_sizes = [len(chunk.page_content) for chunk in chunks]\n",
    "print(f\"\\nChunk Analysis:\")\n",
    "print(f\"- Average chunk size: {sum(chunk_sizes) / len(chunk_sizes):.0f} characters\")\n",
    "print(f\"- Largest chunk: {max(chunk_sizes)} characters\")\n",
    "print(f\"- Smallest chunk: {min(chunk_sizes)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e7f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e748bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: EMBEDDINGS\n",
    "# ======\n",
    "# \n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2f76cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_query(\"Hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f2bc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.1 Creating Chroma Vector Store...\n",
      "- Collection name: pdf_collection\n",
      "- Storage: Local persistent directory\n",
      "- Embedding function: nomic-embed-text via Ollama\n",
      "✓ Added 593 document chunks to vector store\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: VECTOR STORES\n",
    "# ============================================================================\n",
    "print(\"\\n4.1 Creating Chroma Vector Store...\")\n",
    "print(\"- Collection name: pdf_collection\")\n",
    "print(\"- Storage: Local persistent directory\")\n",
    "print(\"- Embedding function: nomic-embed-text via Ollama\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"pdf_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents=chunks)\n",
    "\n",
    "print(f\"✓ Added {len(chunks)} document chunks to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "582660b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.1 Basic Similarity Search\n",
      "Finding documents most similar to a query using cosine similarity...\n",
      "\n",
      "Query: 'What is the main methods available for RAG?'\n",
      "Retrieved 5 most similar chunks:\n",
      "\n",
      "--- Result 1 ---\n",
      "Content: Benchmarks such as SQuAD [33], Natural Questions [71], and specialized datasets for re-\n",
      "trieval tasks are widely used for assessment.\n",
      "Despite its promise, RAG faces several challenges:\n",
      "1. Retrieval Latency: Efficiently querying large databases in real time remains a technical\n",
      "hurdle.\n",
      "2. Data Quality...\n",
      "Source: Page 122\n",
      "\n",
      "--- Result 2 ---\n",
      "Content: hance the relevance of retrieved data. For indexing, it uses more sophisticated techniques\n",
      "like sliding window approach, fine-grained segmentation and metadata. It incorporates\n",
      "additional optimization techniques to streamline the retrieval process [280].\n",
      "3. Modular RAG: this architecture advances be...\n",
      "Source: Page 117\n",
      "\n",
      "--- Result 3 ---\n",
      "Content: Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence of LLMs, research on RAG initially focused\n",
      "on leveraging the powerful in context learning abilities of LLMs, primarily concentrating on the in-\n",
      "ference...\n",
      "Source: Page 118\n",
      "\n",
      "--- Result 4 ---\n",
      "Content: Self-RAG [262] enable LLMs to determine optimal retrieval moments and content, im-\n",
      "proving the adaptive capabilities of RAG frameworks. GraphToolformer [291] divides\n",
      "retrieval into distinct stages, where LLMs actively utilize tools such as retrievers and\n",
      "apply techniques like Self-Ask or few-shot pr...\n",
      "Source: Page 122\n",
      "\n",
      "--- Result 5 ---\n",
      "Content: • Dynamic Frameworks: Frameworks like DSP [365] and ITERRETGEN [320] iter-\n",
      "atively process retrieval and reading steps, leveraging module outputs to enhance\n",
      "system performance.\n",
      "Modular RAG’s flexible architecture anables module reconfiguration (i.e., modules can\n",
      "be added, removed, or replaced) to ad...\n",
      "Source: Page 119\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: QUERYING THE VECTOR STORE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5.1 Basic Similarity Search\")\n",
    "print(\"Finding documents most similar to a query using cosine similarity...\")\n",
    "\n",
    "query = \"What is the main methods available for RAG?\"\n",
    "results = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "print(f\"\\nQuery: '{query}'\")\n",
    "print(f\"Retrieved {len(results)} most similar chunks:\")\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(f\"Content: {doc.page_content[:300]}...\")\n",
    "    print(f\"Source: Page {doc.metadata.get('page', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e42c9406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.2 Similarity Search with Scores\n",
      "Same search but with similarity scores to see confidence levels...\n",
      "\n",
      "--- Result 1 (Similarity Score: 0.6112) ---\n",
      "Content: Benchmarks such as SQuAD [33], Natural Questions [71], and specialized datasets for re-\n",
      "trieval tasks are widely used for assessment.\n",
      "Despite its promise, RAG faces several challenges:\n",
      "1. Retrieval La...\n",
      "Source: Page 122\n",
      "\n",
      "--- Result 2 (Similarity Score: 0.6444) ---\n",
      "Content: hance the relevance of retrieved data. For indexing, it uses more sophisticated techniques\n",
      "like sliding window approach, fine-grained segmentation and metadata. It incorporates\n",
      "additional optimization...\n",
      "Source: Page 117\n",
      "\n",
      "--- Result 3 (Similarity Score: 0.6950) ---\n",
      "Content: Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence of LLMs, research on RAG initially focused\n",
      "on lever...\n",
      "Source: Page 118\n",
      "\n",
      "--- Result 4 (Similarity Score: 0.6959) ---\n",
      "Content: Self-RAG [262] enable LLMs to determine optimal retrieval moments and content, im-\n",
      "proving the adaptive capabilities of RAG frameworks. GraphToolformer [291] divides\n",
      "retrieval into distinct stages, wh...\n",
      "Source: Page 122\n",
      "\n",
      "--- Result 5 (Similarity Score: 0.7030) ---\n",
      "Content: • Dynamic Frameworks: Frameworks like DSP [365] and ITERRETGEN [320] iter-\n",
      "atively process retrieval and reading steps, leveraging module outputs to enhance\n",
      "system performance.\n",
      "Modular RAG’s flexible ...\n",
      "Source: Page 119\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5.2 Similarity Search with Scores\")\n",
    "print(\"Same search but with similarity scores to see confidence levels...\")\n",
    "\n",
    "results_with_scores = vector_store.similarity_search_with_score(query, k=5)\n",
    "\n",
    "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
    "    print(f\"\\n--- Result {i} (Similarity Score: {score:.4f}) ---\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\")\n",
    "    print(f\"Source: Page {doc.metadata.get('page', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dff575a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.3 Metadata Filtering\n",
      "Using metadata filters to search specific parts of the document...\n",
      "\n",
      "Available metadata in our chunks:\n",
      "Sample metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-11T01:48:37+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-11T01:48:37+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'https://arxiv.org/pdf/2501.04040.pdf', 'total_pages': 174, 'page': 0, 'page_label': '1', 'start_index': 0}\n",
      "Available page numbers (sample): [0, 1, 2]...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5.3 Metadata Filtering\")\n",
    "print(\"Using metadata filters to search specific parts of the document...\")\n",
    "\n",
    "# First, let's see what metadata is available\n",
    "print(\"\\nAvailable metadata in our chunks:\")\n",
    "if chunks:\n",
    "    sample_metadata = chunks[0].metadata\n",
    "    print(f\"Sample metadata: {sample_metadata}\")\n",
    "    \n",
    "    # Get unique page numbers for filtering examples\n",
    "    page_numbers = set()\n",
    "    for chunk in chunks[:10]:  # Check first 10 chunks\n",
    "        if 'page' in chunk.metadata:\n",
    "            page_numbers.add(chunk.metadata['page'])\n",
    "    print(f\"Available page numbers (sample): {sorted(list(page_numbers))[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74c0b93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.3.1 Filter by Specific Page\n",
      "Searching only in Page 0:\n",
      "  Result 1: Page 0 - frameworks that integrate external systems, allowing LLMs to handle complex, dynamic\n",
      "tasks. By analyzing these factors, this paper aims to foster the ...\n",
      "  Result 2: Page 0 - architectural strategies that drive these capabilities. Emphasizing models like GPT and\n",
      "LLaMA, we analyze the impact of exponential data and computati...\n",
      "  Result 3: Page 0 - A Survey on Large Language Models with some Insights\n",
      "on their Capabilities and Limitations\n",
      "Andrea Matarazzo\n",
      "Expedia Group\n",
      "Italy\n",
      "a.matarazzo@gmail.com\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5.3.1 Filter by Specific Page\")\n",
    "if page_numbers:\n",
    "    target_page = sorted(list(page_numbers))[0]  # Use first available page\n",
    "    page_results = vector_store.similarity_search(\n",
    "        \"methodology approach\",\n",
    "        k=10,\n",
    "        filter={\"page\": target_page}\n",
    "    )\n",
    "    print(f\"Searching only in Page {target_page}:\")\n",
    "    for i, doc in enumerate(page_results, 1):\n",
    "        print(f\"  Result {i}: Page {doc.metadata.get('page')} - {doc.page_content[:150]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03f59058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.3.3 Multiple Metadata Filters\n",
      "Using complex filter (page >= 0 AND has source):\n",
      "  Result 1: Page 4 - the transformative impact of LLMs across various domains, including healthcare, finance,\n",
      "education, law, and scientific research.\n",
      "• Section 3 focuses ...\n",
      "  Result 2: Page 4 - The central motivation of this work is therefore to investigate the current capabilities\n",
      "and boundaries of LLMs, focusing on their ability to generali...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5.3.3 Multiple Metadata Filters\")\n",
    "# Complex filtering with multiple conditions\n",
    "complex_results = vector_store.similarity_search(\n",
    "    \"research findings\",\n",
    "    k=2,\n",
    "    filter={\n",
    "        \"$and\": [\n",
    "            {\"page\": {\"$lte\": 10}},  # Page 0 or higher\n",
    "            {\"source\": {\"$ne\": \"\"}}  # Has a source\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Using complex filter (page >= 0 AND has source):\")\n",
    "for i, doc in enumerate(complex_results, 1):\n",
    "    print(f\"  Result {i}: Page {doc.metadata.get('page')} - {doc.page_content[:150]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fdb2996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Creating Retriever...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: RETRIEVERS\n",
    "# ============================================================================\n",
    "print(\"\\n6. Creating Retriever...\")\n",
    "\n",
    "# Similarity Retriever\n",
    "similarity_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f49c4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 'What are the main LLM models used for RAG?'\n",
      "✓ Retrieved 4 relevant document chunks\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: RAG FOUNDATION\n",
    "# ============================================================================\n",
    "# final_query = \"What are the key contributions of this paper?\"\n",
    "final_query = \"What are the main LLM models used for RAG?\"\n",
    "context_docs = similarity_retriever.invoke(final_query)\n",
    "\n",
    "print(f\"\\nQuery: '{final_query}'\")\n",
    "print(f\"✓ Retrieved {len(context_docs)} relevant document chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9757488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context that would be sent to LLM:\n",
      "\n",
      "Chunk 1: Figure 64: Final Pass rates of models across LLM Modulo Iterations. Source: Kambhampati et al.\n",
      "[379]\n",
      "3. Domain Adaptability: RAG enables LLMs to integrate domain-specific information,\n",
      "improving performance in specialized areas like law, medicine, and...\n",
      "\n",
      "Chunk 2: Figure 65: Technology tree of RAG research. The stages of involving RAG mainly include pre-\n",
      "training, fine-tuning, and inference. With the emergence of LLMs, research on RAG initially focused\n",
      "on leveraging the powerful in context learning abilities o...\n"
     ]
    }
   ],
   "source": [
    "# Show what would be sent to LLM\n",
    "print(f\"\\nContext that would be sent to LLM:\")\n",
    "for i, doc in enumerate(context_docs[:2], 1):  # Show first 2 for brevity\n",
    "    print(f\"\\nChunk {i}: {doc.page_content[:250]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5ddad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377a80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7079f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f22595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
