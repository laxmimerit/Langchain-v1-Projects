{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd2b4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Core imports matching the tutorial\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import convert_to_messages\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain.agents.tool_node import ToolNode, tools_condition\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./../.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db37bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to existing Chroma vector store...\n",
      "✓ Connected to existing vector store\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: CONNECT TO EXISTING VECTOR STORE\n",
    "# ============================================================================\n",
    "print(\"Connecting to existing Chroma vector store...\")\n",
    "\n",
    "# Use the same embeddings as your ingestion code\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# Chroma Vector Store (assumes data already exists from previous code)\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"pdf_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"..\\\\01 Semantic Search\\\\chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"✓ Connected to existing vector store\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created retriever tool\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: CREATE RETRIEVER TOOL\n",
    "# ============================================================================\n",
    "@tool\n",
    "def retrieve_documents(query: str):\n",
    "    \"\"\"Search and return information from the PDF documents in the database.\"\"\"\n",
    "    print(f\"🔍 Searching: '{query}'\")\n",
    "    \n",
    "    # Perform similarity search using the retriever\n",
    "    docs = vector_store.similarity_search(query,k=4)\n",
    "    \n",
    "    # Format results for the LLM\n",
    "    if docs:\n",
    "        content = \"\\n\\n\".join(\n",
    "            f\"Page {doc.metadata.get('page', '?')}: {doc.page_content}\" \n",
    "            for doc in docs\n",
    "        )\n",
    "        print(f\"✓ Found {len(docs)} relevant chunks\")\n",
    "        return content\n",
    "    else:\n",
    "        print(\"✗ No relevant documents found\")\n",
    "        return \"No relevant information found.\"\n",
    "\n",
    "retriever_tool = retrieve_documents\n",
    "\n",
    "print(\"✓ Created retriever tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c538b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Initialized chat models\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: INITIALIZE MODELS\n",
    "# ============================================================================\n",
    "# Using ChatOllama instead of OpenAI\n",
    "response_model = ChatOllama(\n",
    "    model=\"qwen3\", \n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0\n",
    ")\n",
    "grader_model = ChatOllama(\n",
    "    model=\"qwen3\", \n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"✓ Initialized chat models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d810ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: NODE FUNCTIONS (from tutorial)\n",
    "# ============================================================================\n",
    "\n",
    "def generate_query_or_respond(state: MessagesState):\n",
    "    \"\"\"Call the model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply respond to the user.\n",
    "    \"\"\"\n",
    "    response = (\n",
    "        response_model\n",
    "        .bind_tools([retriever_tool]).invoke(state[\"messages\"])  \n",
    "    )\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d98802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document grading\n",
    "GRADE_PROMPT = (\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question. \\n \"\n",
    "    \"Here is the retrieved document: \\n\\n {context} \\n\\n\"\n",
    "    \"Here is the user question: {question} \\n\"\n",
    "    \"If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\"\n",
    "    \"Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\n",
    ")\n",
    "\n",
    "class GradeDocuments(BaseModel):  \n",
    "    \"\"\"Grade documents using a binary score for relevance check.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
    "    )\n",
    "\n",
    "def grade_documents(\n",
    "    state: MessagesState,\n",
    ") -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
    "    \"\"\"Determine whether the retrieved documents are relevant to the question.\"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = GRADE_PROMPT.format(question=question, context=context)\n",
    "    response = (\n",
    "        grader_model\n",
    "        .with_structured_output(GradeDocuments).invoke(  \n",
    "            [{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    )\n",
    "    score = response.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        return \"rewrite_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97f1da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question rewriting\n",
    "REWRITE_PROMPT = (\n",
    "    \"Look at the input and try to reason about the underlying semantic intent / meaning.\\n\"\n",
    "    \"Here is the initial question:\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"{question}\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"Formulate an improved question:\"\n",
    ")\n",
    "\n",
    "def rewrite_question(state: MessagesState):\n",
    "    \"\"\"Rewrite the original user question.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    prompt = REWRITE_PROMPT.format(question=question)\n",
    "    response = response_model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [{\"role\": \"user\", \"content\": response.content}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f9d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Defined all node functions\n"
     ]
    }
   ],
   "source": [
    "# Answer generation\n",
    "GENERATE_PROMPT = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, just say that you don't know. \"\n",
    "    \"Use three sentences maximum and keep the answer concise.\\n\"\n",
    "    \"Question: {question} \\n\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "def generate_answer(state: MessagesState):\n",
    "    \"\"\"Generate an answer.\"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
    "    response = response_model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "print(\"✓ Defined all node functions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c69fb64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Assembled and compiled the graph\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: ASSEMBLE THE GRAPH\n",
    "# ============================================================================\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(generate_query_or_respond)\n",
    "workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
    "workflow.add_node(rewrite_question)\n",
    "workflow.add_node(generate_answer)\n",
    "\n",
    "workflow.add_edge(START, \"generate_query_or_respond\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_query_or_respond\",\n",
    "    # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"✓ Assembled and compiled the graph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8187cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAHICAIAAADr9fs8AAAQAElEQVR4nOzdB0ATZxsA4O8uYe+pIoqgiAMVt7XWvbXuuvfA3bot7llbd9Wqtda9FX9Ha62j7r0HOJChDEEFZJNAkv9NDmKAJCSQdcn71J8/uZXL5e6973u/u++4IpGIIIQQe3AJQgixCoYthBDLYNhCCLEMhi2EEMtg2EIIsQyGLYQQy2DYUsnTaynvXmdlpubm8IW52QUvGaEJERaZgRIRCoZT0gEcMyLIKToZIbAwWiQ7pVy0GRHmyJmS5hJhrrzpOYSiiJkl7e5p5VvXzrOqBUHIWFB43ZYS5/Z9iH6VmZ2Vy+HQ5pa0mTlFcykBv0CUomhKJCyyDWn4jxLKDOeYUYKcIpNJwlbhJTCxrNDyzChhjqjoZzHDSRFcLidXIORlCSiKgr80h7Kx5zZo41LjK1uCEMth2JLv9B/vY8IyzS3oin42zXq4W7H8YH/zKOvBpcSkeJ6ZGd30W9caTewIQqyFYauwTzH8/22O5ZpTLfuU9fa3JMbl4sEPrx6k2jmbD5lTkSDEThi2Crh+IvHp9c/12jo36ehEjNeBX6JTEvnjV1YmCLEQhq0v4sKzT/4eN36lDzEBd898vn/x04Q1VQhCbINhK8+VY4mvH6aO+cmbmIw3jzLPHXg/YRWWuRDL0AQR8vJexot7n00qZoEqda0bt3fZFhRBEGIVDFti/x2J7zi0HDE99ds52jmbHVwVTRBiDwxbZP8v75zczCvVtCYmacDMCp8/8sMfZxKEWMLUw1ZWuij5A3/ArArEhPnUtP3vaDxBiCVMPWwF/xbj6GrqN750GFaGzxNGPM8iCLGBqYetlA+8pl1ciQ6Fh4d37dqVqO/IkSMLFy4k2uHsbnH3n08EITYw6bD1+EoKzaV9alsRHQoNDSUlUuIZVVHzK/vPn3IIQmxg0mHrzeN0GzsO0Y60tLRVq1Z17979m2++GTt27IkTJ2Dg1q1bFy9eHB8f36BBg/3798OQa9euzZs3r0uXLs2aNRs3btz9+/eZ2Q8dOtShQ4fLly83atRo9erVgYGBf/31199//w0zvnz5kmha7W8cRCKS9F5AEDJ4Jt1xTfrnHOey2kpsQXhKSEgICgry9vaG+t2KFSt8fHwgMPH5/HPnzkEMgmmys7MhZkFggonh7YULF6ZOnQoBzsXFxdzcPCMj49ixY0uWLKlRo0bFihWHDx/u5eXFTKkNXDPqxd3Ur7sb811NyDiYdNiCPLSTuznRjocPHw4dOrRJkybwevLkyW3btnV0dCw0jaWlJZSqrKysmFH+/v4Qpx4/ftymTRuKoiCoDRs2rGHDhkQnuOZ0UkI2QcjgmXTYEgqInYu2KokBAQH79u37/PlzvXr1vvrqq+rVq8udDIpUmzZtevDgwadPeRnx5ORk6diaNWsSXaE4wuxMrCQiFjDp3JaIIiIh0ZJFixYNHDjw1q1b06ZNa9eu3ZYtW3JzC/dDCkmu0aNH5+Tk/PTTTzDl7du3C00AVUWiKzShKYIQC5h0aYumqMxUbcUte3v7kSNHjhgx4smTJ5cuXfrzzz/t7OwGDx4sO8358+ch1QXpKqgnkoLlLN0T5IrMLLRV9kRIg0w6bHHNSPIHPtGClJSUs2fPQjMiZK8CJF69elW0BRAmg+jGxCxw8eJFoj+5OSJHdzOCkMEz6UqitS3nU5xWktBcLnfbtm2zZ8+GolZiYuLff/8NMQuCF4yCNkFIY12+fPnt27e+vr7wOjg4GOqPN2/evHv3LuTmoeYod5kVKlR4/vz5vXv3kpKSiBbwsgW+dbCzZsQCHEjBEFMFNcTo15kN2zkTTYOcVK1ataAOuHPnTkjMR0dHjxkzpkePHtA+6OrqGhoaumvXLohQ/fr1EwgEBw4c2LBhA9QQ586dm5mZuXfvXohlbm5u165dg8wXTeedWpycnGDIwYMHGzdu7OnpSTQq7GFGxPOMNv3dCEIGz9S7Cdw07U2/6RXdyusu822YgjfEZqbnDpnjRRAyeKZ+T6KlDef8fuz8gHyIza79tSNBiA1M/fGu7QaW/Wt7rJIJTp8+vWbNGrmjeDyehYX8i+yh6t2yZUuiHVOmTHn8+DFRc5X27NkDaTW5o64e/ygUiOq0cCAIsQH2JU+2z4twcDX/bor8bFFGRga098kdlZqaCu2Ackc5OztDGyLRDsh88fl8dVfJ3d0dGgrkjto8803dVi5fdcbbehA7YNgS2zj1zYTVVTgmedHSqS3vP8bzRi2uRBBiCeyUWcy/iT2UuYjpiY/IjY3MwpiF2AXDllirfu4uZc13L31LTMzxLW+/m2LSHVIjNsJK4hd3ziQ9uZESuNwkHjuWkijY91PksPneto54Qw9iGQxbBRzfFPspltdvipdDGWM+mP/d+yHsUeqAmRVdypn6BWuIjTBsFXbr76RHl5LdPCy/m1aeGJ3IZ1kXDsULhaKxK3wIQuyEYUu+vT+9S03KcXQzb9Da2a+hDWG/y0c+hj1Jz+ELK9ey7TC0DEGItTBsKZTyUXB2z/ukBB5FKHMrysaBa2PHpbmUILdgXzcUIZJNSHMooUAkfSseQhOhkFA0DKOggFNoLg5NCQQiGCvt80t89yHMkps3o3gqSjKpeJl5P5R4lIiiKJF0meIlwGIo8uWtkHC5lEhIZabl8jKF6WmCHJ7A3ILjVd2mw1B3ghDLYdgq3pvHma8fpH7+xOfzRFBayeXL32IULYJIUWAIBQEFYg78jyq6mZn4Ip5GCP+JaJqG1zChUEgxM0omEv9C4qEkLxpKRonjFsnv45CSBDWIW9JIB3NwOOI5IZI6OJm7VrBs0snZyhY7AURGAsOW/oWGhv7888979uwhCCEVmPo9iYYgNzdX0W03CKGi8GjRPwxbCKkFjxb9w7CFkFrwaNE/CFtmZtiJO0KqwrClf1jaQkgteLToH4YthNSCR4v+YdhCSC14tOhfTk4Ohi2EVIdHi/5haQshteDRon8YthBSCx4t+odhCyG14NGifxi2EFILHi36Byl5vNwUIdVh2NI/LG0hpBY8WvQPwxZCasEHjukfhi2E1IJHi/5hbgshtWDY0j8sbSGkFjxa9A/DFkJqwaNF/zBsIaQWPFr0D8MWQmrBo0X/sHdThNSCYUv/sLSFkFrwaNE/GxsbDFsIqQ6PFv3Lysri8XgEIaQaDFv6B0UtqCcShJBqMGzpH4YthNSCYUv/MGwhpBYMW/qHYQshtWDY0j8MWwipBcOW/mHYQkgtGLb0D8MWQmrBsKV/GLYQUgv2bqp/GLYQUguGLf3DsIWQWrCSqH8YthBSC4Yt/cOwhZBaMGzpH4YthNSCYUv/MGwhpBYMW/qHYQshtWDY0j8MWwiphRKJRATpQ+/evSMiIiiKYt4yL5ydnc+fP08QQorhdVt6M3bsWFtbWzofhC2hUFivXj2CEFIKw5betG/f3tfXV3aIu7v7kCFDCEJIKQxb+jR69Gh7e3vp2xo1avj7+xOEkFIYtvSpadOmVatWZV5D/Bo0aBBBCBUHw5aejRo1CtLw8KJatWoNGjQgCKHilKQlMfxJVuTz9KzMHOkQSCgLhaL814SICPMOXguFhKKJSMh8mngUM5D5K50mb204MAG0qIm+DKHE/6RvC00POBxaIBAqGivOdNOUIFdmEEVomQXmrSF8pKiYIeIIL7sYWvxthAWHwNeUfMUCA4FIZrKiW+x5SEhychLUEN3dXQW5cn4OmksJ5Q4v+GWlX1C6kUWw9WTmY75U0bmkP5CcBcp867zJ8od8+VmLrAxsc5Gw8ApLN2mhT5FOXHhvKfrNFI+SMjOjbe3NvurqwjEnyFipF7YEfLJrSVROjtDMnOZnf9mDZPcnShK2mKXmHckFw1bhgbLhQHyQUZK4JR1CCrwtsu9CpBMJZFaxSHCBJRSYgLneQFRwaZTSIZLjTTaQ5X0QKfBZebMUjlsFPk7ueoq3lkhEUzTNoYQCuWGLCOVd1yX/MJbZyCJK/F+hUYU2kexyii5Q9lvnbxkRYZZZZFPL/mpyvrJ0YOFNlL9AmTWXS5WwxTGD7Uj4PJGzu0X/meUJMkZqhC1+FtmxMLJGI+e67RwIQobt+KYYGxu6zxQPgoyOGmFr6+zIFr3Le/ph4Ruxw19bYyiOqP+MCgQZF1VT8v/sSLC04mDMQizSdZxnUgKfCAgyMqqGrY9xPAdXM4IQq0AS9tY/yQQZF1XDFi9LSHHxagnEMtAym5WOt6kbG1V7gMjNFQpycghCrCIUigQC7CzA2GDHNciYiRucMGoZHQxbyJiJewOiCDIyKoct/PkRS+F+a3RUDltY2EYsJLk5DHdcY6Nq2KIk944RhFhFfGOmAPdbY6NOJREhhAyA6il5jFuIlURYSTQ6qoYtcR8FQvz5EfsU6AMDGQW8AAIZM4oWUXhzh9HBCyCQMRMJqWK76EKso2rYglZEmsbTFkJI/1SNRNCQLBTgaQvp0/pffx4xqq9as4ivksezrdFR9SeVXLZnDLXExUt+PPPPSYJMg/ieRDzbGh1Vw5ZI0uE5Yb9Xr0IJMh2YkzVGWmxJDA19BqX6mNh3tWrVHTp49NZtv/p4V5k6JQhGJSUlbt6y9nnIk+zs7IYNv4KxFSp4wfDIyPCRo/tt/m33gQM7r9+47Obm3qpl+8AxkzkcDowNCXm6e8+2ly9DHBydvmryzbChgTY2NjA8+PihAwd3wpIXLprVo0ffyRNn3Lp17b9L/z599ig1NaV6Nf8hQ0bXDRA/y6tVG/HfVauXbtm67vTJy7m5uX/u2Hz7zvUPH+L9/QN6du/bpEmzYr9XZmbm8hXzHj68C7NPnDD906cPV6/9t2dX8IuXIRMmDoOVr16tJjPl4CE9mjZtMWH8VCVfudDKv3nzysLcYuUvm6QfN3/BjMSkT5s37VK+SmvX//T48f20tNRKXj6dOnXv0f07GB4R8WbUmP4rlq9fvXaZo6PT9m0HlSyke882sFZXr//39Omjkyf+s7ezP/vv6VOngyMj33h7V2ndqn3vXgOYEndaetrOXVvv3L6e/DnJr2qNtm07dencA4bPnT/NjGvm5eV96PAeoVAIP/fMGQuqVMl7EOSevdv/PfcXbC5397IBderDV2aypT16tR0xfFxKymf4ca2srBo2+GrSxBkuLq7STf3o0T1Yge7f9iElYCynWyRL1dIWh0Op1U0gHJxz5k11cnLesf3IqJETftuy9uPHBGanFwgEU6ePffzkwdQpc3ZsP+zk6AxHe2xcDBE/LUrcgeqatcvatOl47uytuUHLjhzdd+nyeRgYExs9Y9aEbF72po07ly5eHRERNnVaIAQOGGVubp6ZmXHq1LGgH5dA6IGPhn2dx+P9OHvxT8vXV6xYae68qRA1YMqzZ27A35kz5kPMghcbNq48FnygZ49+B/afbtG8zcLFs65cvVjsV4MAEREetn7dH4cP/h0T8+7CxX+Y1VZCyVcutPKdO3Z/8PAus7bMZoSow2TlLQAAEABJREFU2r5dF+XL/3HO93FxMUuXrDly6Ezz5m1+3fALxFDp9tyzb3u/vkOmT5unfCEw8V9n/lelit+qlb9ZW1lfuHj2l5WLq/pWO7Dv1OhRE2FDbdq8hply5crFoSFPp0wJ2rXjWPXq/uvWr4AzCgzncriPHt8nku28e1ews4vrvAXT4LvDEAhzJ04eGT92yrGj/8L+cPnK+aPH9ks/9/DhPRDCTvzv4u6dwc+eP961+3dm1Oo1S2ELr161BX7xyKhw2BRETZT4+XJY3DI2qkYigUAkylUjSQB7GJw/xwb+ULZsOdj1x4yelJAQz4x69uzxu3dRc4KWNm7U1NnZZfy4KfYOjsHBB6TztmjetmWLtrA316lTz6Nc+devX8DACxf+gTM57L4QhipV8pkxfX7Ym1dQIiOSJ5TB4d2//7C2bTp6ela0tLTcvu3Q9GlzoYQF/8aNnZKVlQUHQ6E1hLgGJ/+BA4Z3+7a3g71D507d27TuuGfvH8q/V3p6+pUrF/r2HeJXtTqs/MQJ07hcs2LP50q+cqGVb9WqvbW1NRQVmRmZL9i6dQeibFPfgOXPnD4fSnkODo6DBo6oVSsASi7MwuFvwwZNvuszSFoGVAQmtrd3gLJqg/qNuVzumTMnateuO+WHH+HcU69uwxHDxp04cSQ5OQmmfPL0IQRHWKy7exkoC/+2aZeLixuzED6fN2TwaFgU/HBQhoIfHdYNSmcHD+2G4c2atbSztYMfF04V+/b/mZPf8WT58hUGDxoJo6CQBaUt5hf/9OkjnLEG9B9Wo7o/bLSxgd9bWFgS9YmwDwCjo0ZKnqhz1oKaha2trY9PFeYthA87O3vmNUQQCElwJOQvmYIqAxwJ0nmrVq0ufW1ra5eenkbENcQn1SSHJTMcoqGHhydUA6VTVvP7clhC+WXjplV9+naEWmGnLuJ63+fPhTsUh2ODz+fDQSIdAqsBtaqU1BSi2Lt3kVDEq5YfAmDlobhRfNgq7itLVx4KX23bdIIYzby9du2/r5u2sM/fdHLBpoZI7e1dWTqkqm912RQevCWqgRof8wKqeFCfld04des2hIHMBoewCKXgLVvX37x5FUIPRHD4OZjJoDYHIY957Vm+Ivx9+y4yOvotTAYb6ssqVa0OJ4DY2GjpW+ko2E8yMtLhxfv3sfDXy8vny+r51SBqknQTiKUtY6P6zT2EqJMjgBOstbWN7BDIrTAvIAzBTsykmYqOJUT+BWIw18tXoYXmSs6vTBHJAc+8gDP8D1NH16vbaP7cn2rUqAUxol2HJnIXCH8n/zCq0HBYJhS+iAJM9Q3qUNIhsq8VKfYrS1cedO3S68TJo1CFdHF2vXP3BnwL5QtPTPxkaWklOwTKa1lZmV8WbmFBVCNdDQjosMKQ+IN/shMwpa3ZsxZBrRaKhBC8bG1se/bsN3TIGCZaWcoUiCCYwl+IQUlJnwqNspJsNOlKym2kTkn9TApuXquCXxOZLG2l5GEfhV1fdkhi4kfmBVQEIPO6fNk62bEcmqN8gZAogZM81DtkBzrYOxadEvIm8NGQ2IJPIfLKWXmr4Squ10BdEmoossMhYUwUY4p7PD5POiQjM0PRxLmCvIcvqPWVK1f2hYLJP/+c9PWtBod348ZfE6WgXSI7O0t2CKySa36trWQg4kDsg5waVAZlh3uU84S/UPqDOh3URp8/f3Lt+qW9+/6EQnHf7wYTSZCSTgyVX/gLNTsbG1t4kSWzkpmSjebs7KpkHZgfF7KZheZSD8U86hwZFVXDFocmNJdDVAaxAOIFlE0gKwFvIVMLrULMqMqVq0KyCaJDeQ9PZkjc+1hHByflC6zs43vu/N91ateTlsWioiIgGVR0Smg9hIoGE7OAoiw7VGEsJMUQppGRSIoSUN2Dw5UoVras+CnH0JoJCTsiqUxBctpCUqyAFkAiU4KAShBkZ0r2lSHRBo1xkI2GCqO0zqUI1OwgQECmz7eKHzPkxYvnlWTqjCUD6wxFZunGgcIX1NogmQWV6IsXz8IaQmiDEwn8g9bP12EvmcnCI8Igp8kEdyZFBYkCWBS0BUM1X5pfgzWETBa0FCtZAWZTQ2T0k1QhYQXuP7gjW0RVheT6B6wkGhuVU/JCIsxV4zmZTRo3gz0VEkwZGRnQCLh373bpPlq/XqNGjZquXr0UanOwi0OFaNz4IWfPnlK+wD59BkGMgMYsOEQhV/L7tg0jR/eLiHxTdEofH1+oN0HLPSSh7ty9+fDhXTiKPnwQNwhAnILVuH//NoRRqBANHzYWcvCQM4bSGUQ3aKlc/+vPylcDZvf3r7P9z9/gS0FUgka0tPRUZlSFCl5wKJ755yTEPvjon1culKbz1P3KrVt1gMIp1BAhOpDiwJIhzbd27XKoRMN5Aqp1EBT6fTeElM6YUZNu3LgMXwc2O2yiJUuDps0YBxsKmgsh379oyWwIKPBx5879HfbmZS3/AGYuSOpD+2xqWir8g21bpkzZ2rXqQumsXdvO+/bvgFwYDIdZ/nfiMPygym8XYzb1rl1b4eeG9pNly+eW4IJnSGwI8QIIo6PGPYlq9W4K1aKpU4LgEOr9XXuo7AwbGgghDBrdmLErlq+HsLJkWVBo6DM42tu27dSrV3/lC4Rd/8/thw8d2j12/GBolYOk+MwZ85kiTyFtWnd4+zYCjhmIKdDaBYkYKLkcOLgrLS112tQ5gwaOhMb4u/duHjzwV/9+Q6EgcODQLghtUJGpWaP29Onziv1qQT8uWb9+xZjAARBAW7VsB+2eIaHi5n9Ius+fv+LXDb+0btvQ1dUNWlHhqJZm69X6ylDiq1+/8ccPCd4qFJqgOLZsyZqtv6+fMHEYxGKI2kuXrIZCECkdWMK2rfv3H9gJZwiohMLGWbZ0rYXEkkWrNv62ikkLwhpCW22njt2YuXy8q1SqVLlvv04QaMqV9Vi2ZC1zzd3ECdMhSC1dPgcCOgTZgQNGQBNhsevAbOrAcYOgqNWxw7cQxJmmVbVgacv4UCpejLdldoS7p3n7oZ5EZZBUhuIG0woGn9K1W4uRw8f37j2AGBcooEGb4M4/jxDNgULNd/06BY6ZzFzGyRYLF82Cxoc1q7cQg7F3WbhvgF27Qe4EGRGV+5JX8wIIqArByb9K5aqjRk10cnL+88/faIpu2bIdQUrFx7+PjYs+/r9DXl7eqtQQkXLqtoAjVtBWSyKkk37+6dc/tm9asHAGn8eDpjHJRYmuxOBBHmfO3CmKxu7be0J67Zg2XPzvLCTOoAq8aMEv0lSORlZJv99Lr7CSaGxUrSRumxPp5mnRdpAHMQHv4+MUjSpXVj9bQCOrZIDfS9v2LQ+vUte23YAyBBkRVUtbAoHIdPrbMsBjWCOrZKyxSQkh7LP4wDGjo0Zui8LeTRHbiCvaNOa2jI3qT6XGO1IR+4hzIEIsbRkb1R+BgZe/IIQMghqPd8Xu1hDrSDoTx/3W2KgetkTG0Zc8MimSzsRxvzU2aoQtvGwPsQ5NQ0sS7rfGRvWUPIVRC7GOUCgSYkre6KiRkseHkiOEDIHqvZuKREIsbiGE9E/VsGVhSZlbafHpZAhpg7klB/4RZFxUjUTWttzMFDW6CUTIEAhyheUqleR5P8iQqZqvqvmV0+ePPIIQe4TeSuXQVNUGNgQZF1XDVq1mtnZOZsFrYwhCLPHwUmKTLthBoBFS79r3f/d8iAnL9PCxLl/FTiDMUbxUIrmBMe//CqEpKr977yITyA6gKNkrxaAls/Cq5k8g52Mko2jJ9dFFv6D4slkRVfQeS3E7OU1EQgVfqOD6EOaJMOKOqot8AjOlzGoxL/O3ikj2yX1536vQwqVvZYcX/L7izUhI0ckokv/VJNOJ31LSyfI+uug00s70RJIVkvkW0iXnzyS7/l8WlPcOJpftu112yXnLJF8GwGfRokJjv/ww+Z9f8Hen8j9f5lMly8p/x6VyMklUSNqnuOz+M7yc3DGxZYTUvmXnSnBSxNNUHk+Yy1Pcjw2V9yxgSvFYQuRNUGh3FCkYxRAV1wFcwR1aZj6Rwhss5UdaxXMpnl7RKBFV8AlYcreVdBNRIqrIRd55a6Lko2UnU2XdZN4WXj3ZaUiRTyyyHCZcq7gazPeWjhOJCnT8nrdN5H7NgvuJ7IfSHIprRtvYczoPq+hkcv30mAoTutMQvmlGRkaXLl2WLVv2zTffEIPx8uVLWKV9+/YRkxEcHLx169bk5MKPsPTy8oJRBCGlTOIS0qysrDVr1sBBQtP0lStXDCpmAQ6HU758eWJKevfu/f3337u5FXgGrVAoXL16NUGoOEZe2oKAZWVlNXfuXH9//wEDjO2hQWx3/vz59evXJyQkMG8hjVWpUqXc3NwWLVo0a9asQYMGBCF5jDZs5eTkwKnb09NzyJDSPuhU23g8XkpKiru7KbZ5Xb9+fcWKFUzk8vDwOHXqVHR0NJSIYfiLFy+a52OeH44QwwjDVmJioouLy/3799++fQuVEWLwHj58CImebdu2EZMEv9TSpUvfvXv36NEj2eGQiLyaLyAgAKr2UAorV64cQSbP2MLWpk2b4ER96NAhwh7Pnj07duzY4sWLiakKCQmZMmUK1BkVTXDnzp1r165BKczW1haCF4SwmjVrEmSqjCRsQS3j06dPsCufO3euffv2BBmpsLAwCF4QwuLj45n6o6E1sCAdMIawdevWrWXLlkEli6XtcdnZ2enp6a6uLHj2reGAVABTf4TCNZPCh79OTk4EmQAWh62YmBgoW40cOTI8PLxy5cqEteDYO3ny5Jo1awhSH+zATAof/kILDFMEY/X+gIrFyrAFrYTQWN6nT5+goKDGjRsTlrt9+zZErlmzZhFUOpAlZIpg0DgLlUeIXw0bNiTI6LAsbEHVYO3atWPHjoXzKo2Pm0UKQEkc8l8Qv54/f86k8CGEWVlZEWQUWBO2mMsaoKHQ19e3Q4cOxIhkZmZmZWXBtyNI02DDMil8CGH+/v5MFdLU7kkwPiwIW1DgX7BggZ+fH6SxiDE6e/YspGagVYEgbbp37x5ThYRiFxO/IJARxEIGHbZevXoF0SoiIiIqKqp169bESF2+fPnp06fff/89QToBbThQBIP4FRcXx1zFCiGMIPYw3LC1bt26+/fv79+/nyCkHUlJSUz9ETD5L+Ds7EyQYTO4sPXixQvYmb7++uuHDx/Wq1ePmICMjAw+n4/XHOmX9EYiDw8PCF5QBMOrKAyWYYWtu3fvbty48ZdffoFdh5iMo0ePQkV49uzZBBkAaHxk4hek85mr8Bs1akSQITGIsBUSEnL69Okff/wxISGhTJkyxMT8/fff8fHxo0aNIsiQxMbGQvCCWiRkHpn8F15FYSD0HLagfmRjYzN+/PixY8cGBAQQhAxPdnY2xC8mi49XURgCvYUtOJUtX778hx9+gLZCYtrS0tKEQqGDgwNBBg+vojAEeghbkZGR3t7ekNDx8vLCrAHYs2dPSkrK5MmTCfD6rncAABAASURBVGIP6VUUcAJmUvh4FYXO6DRs8Xi877//HtoHoUpIUL7g4GCohgwaNIggFkpOTpa2QuJVFLqho7B1+/ZtKEtD2IqKiqpfvz5ByBjhVRS6oYuwtXbtWmjg//XXXzkcfNamHFBDpCjK3t6eIGOBV1FolRbD1s2bNz9+/Ni9e3coYVWqVIkYr5ycHKjlkZJ68OCBmZlZ7dq1SUlBepjL5RJkePAqCm3QVth68uTJjh075syZYwrXYTHdk5KSyszMpGna0tKSlJStrW1pZkc6gFdRaJCGw9b9+/ehXWzDhg1wGMOxRExDKcNW6WHYYhe8iqKUNBa2oD7o5ua2dOnSfv36Va1alZiSUoYtoVBISZCSwrDFUngVRcloIGy9fft29uzZUB8sTXaG1UoZtmBeaKwoTb4Dwxbb4VUUailV2IJccv369S9fvuzp6VmlShViqkqf24KwVejBy8uXL4dlrlixQpUlYNgyJngVRbFK2PwkEAgGDBjQtm1bCFstW7YkqKBTp069fv16xowZqkxsbW1NEMrHFLVI/lUUc+fOzcrKYopgeBUFQ+2w9e+//0L6ENJYP//8s4+PD0HyhIWFqT5x6XNbyCj5S0yYMAEyX9euXdu1a9e0adPwKgqibiVx48aN8fHxixYtMjMzIyhfoUrizJkznz17xrzetGkTVJ9v3bq1b9++6Ohoe3t7KPBPnDjR3d2dmQBGQdtrTEyMg4OD7CjZSuLdu3ePHTsGxTcnJ6eaNWuOHDmyUNYDK4kmAq+iYKgUtv7666+4uLjAwMCkpCRMExZVNLc1ZcoUyPcxlcSHDx/OmzdvzJgxrVu3htMmhH4oqy5ZskQ6aujQoVDd/vDhg+woadh68+bNpEmTmGmg9WPnzp0QvGCs7Mdh2DJBha6igFpkrVq1iGkovpL46tWr+/fvT506FV5jzCoBKEx9/fXXPXv2hNdQpILoHxQUBEWnqlWrMqP69+8Po1xdXWVHSWcPCQmBkATT0DQNBTEYFRUVRZDJaygxffp05iqKtWvXQpndRK6iUPiEVIjiPXr0gBeQwIJaIfYGVWKRkZGyfYoxIQlOBtJRkNtiyryyo6SgVgiluQULFhw/fhwKa/BD1KlThyCUD3ILkDeAYviRI0dq16598uRJCGeQBTtx4gSfzyfGSGHYgnP+77//Di8wjVUaGRkZPB5P9uIGJpOamZkpHQWvc3JyZEfJLgFSY0uXLnVxcdmxY8eoUaOgOAblL4JQEZA96N69+5o1a6D+CGUOqCTB2Y4YI4Vha/To0SbYrbvGMQFL9kZrJipBdVvJqEILgZMnVNJ3794NNYLU1NSFCxfm5uYShBSDeuKIESOgOE+MkfywdUiCoFLjcrm+vr4vXryQDgkNDYW/3t7e0lGQUDc3N5cdJbuEp0+fwskTXkCBq127duPGjYNUfUJCAkHIVMkPW6kSBJWUh4fHy5cvHz9+nJyc3K1bt5s3b0KiIS0t7cmTJ9u2bQsICGBuKmBGQdIKtnahUVIQy6Dd8MyZM58/f4ZlQuYC4hcWhJEpk9+SCO1WBvu0albo3LlzWFjYnDlzli1b1rZt28TExGPHjm3duhWaAuvVqweld2YyZlRwcDAErEKjpHr16gUBC+bdsGEDFMqgnWjlypXYuxYyZQb3VGo2KuU9iZCbhzBU6J5EteB1W6io8PBwOHEePnyYGB35J20mscVcT4S0zcbGhiCEVCY/bGFiS5fwnkSE1IK5Lf1jOq7B/sURUpH8sIVPkdElmqaxqIWQ6jC3pX/Y3xZCasHclv5hbgshtWBuSwMsLS2Zy9xLZs+ePRYWFv369SMlhSEPmRTMbWkG5KdISUHUoyUIQkgFmNvSP9zOCKkFc1v6B1sbquTYoxlCKsLclv4FBwdnZmZOnDiRIIRUgLkt/XNycuJwOAQhpBrMbekf0/k1QkhFmNvSv/T09NzcXEdHR4IQUgHmtvTv7Nmzb968+fHHHwlCSAWY29I/BwmCEFIN5rb0r50EQQipBnNb+sc8eQwfnYuQijC3pX9Xrly5c+fO4sWLCUJIBZjb0j87OztsRkRIdZjb0r9vJAhCSDWY29K/rKyszMxMFxcXghBSAea29O/evXsnT55cs2YNQQipAHNb+mdtbY1FLYRUh7ktvenSpUtcXByHwxEKhfD22LFjFEXB60ePHhGEkGLye9RMlSBImwIDA21tbYmkZ1Rp76b169cnCCGl5IctKGeVpmtzpIru3bt7eXnJDnF0dBw8eDBBCCklP2xBbgvvktMBCFKyaUQfH5+WLVsShJBS8sPWIQmCtKxjx45VqlRhXkOFsU+fPgQhVBzMbenZgAEDmIItVBg7dOhAEELFweu25Ih+lZWZJhSJBIR5/KBI/CRCIhLBO8n/iGS4eAghRDoNtAOKiPg/yUDJUMkEkjmY2fKeaCjdtvCunF2DBn7dYmJiOjTt8vJeqvg8IsxfgkiUP9uXISR/iV/eSj8DVkD2V6MlExT5GTkUt5yPtS3euI1YC6/bKuDUtoT3ERkiIREIhKK88EGKHvnyB5Z0eAWLLhUqk6SX5MLLD6RkpMFUhXMN14wSiihzK7pVjzKV61kRhNgGr9v64t/dHz4n8Fr28vTwK/kjptni7pmk80fj3SpVtHfGp28glsF7EvMcWxf3OSmn3wwvYhoadXaGf3uXhvccX75cZUuCEHvgdVsSfPIhLst0YpZUBT+7s/vjCUKsgtdtiV0+mWhuySWmp843jtnpAoIQq2BuSyw9JSe/Ac+0OJUzF+ZiVx+IZTC3JZabIxDwTfToxQ6KEOvgdVsIIZbB67YQQiyDuS2EEMtgbgshxDKY25KgROJ/CCE2wNyWhIiS3CSNEGIBzG3lw6iFEEtgbisf1hERYgnMbTEoky1t4QV6iHUwtyVG5Xf9Z4IoCqvHiGUwtyVBE2xJRIgtMLclJu7IVE93Ui9cNCs9PW3N6i0EIaQazG1pXWRkeNDcHw4d+Evu2ObN2+Tk8AlCSGWY29K6V69DlYxt0xqf1oOQevA5iWIi9cuWULlbsjTo920bWrVpcPXafzAkJOTprNmTunVvNWRYr81b1mVkZMDAnbu2/rJycUJCPEx29Nj+iIg38OL27et9+nYcHTiAWc70GeOZZSYlJS5bPrf/wK49erVdvmJ+dPRbGHjv/m2Y5fnzJ9KPfvEyRLyQOzcUfShCxg2fkyhGc2iKVm8WMzOziMg38G/50rW1a9WNiY2eMWtCNi9708adSxevjogImzotMDc3d8Twcf37DS1Tpuyli/e/6zMI5oJ59+zb3q/vkOnT5skuUCAQTJ0+9vGTB1OnzNmx/bCTo/OEicNi42Lq1W1oZ2vHREbG9euXYEjDBk0UfShByKhhX/JiIqFI3ZQ8RVHx8XGLF65s2rS5o6PThQv/mHHNIHZUrFipUiWfGdPnh715df3G5aJzwV+IOBDCqlerKTvq2bPH795FzQla2rhRU2dnl/Hjptg7OAYHH+BwOK1atb967aJ0Sghhbdp0hOEqfihCRgb7ki85r4relpZ5z7wJCXlSrVpNBwdH5m3ZsuU8PDyfPnskd8aqvtWLDnz2/DGUxaBsxbyFABdQp/6Tpw/hdcuW7aCa+TrsJZEk+GNi3rVp3VHdD0WmBnYhCwsLYozwui0xcQ1R/YsuzWX2ifT0tJevQiHlJDtBclJisTPKLiEnJ6fQEqAcB38hfjk5OV+9erGqb7Vr1y+5ubn7+9dR90MVwQZjYwUJWx6PR4wRXrclJnkAdakuFnd2ca1VKwAyWbIDHewdVV+Ci4urlZXV8mXrZAdyaPGzV+G0CfVEqP2NHjURElvt2nbW1IcSvIUcsRBetyVVqu9b2cf33Pm/69SuR9N59e6oqAhPz4pqLKFy1aysLHf3suU9PJkhce9jHR2cmNetW7Y/fvwQNEFC9gryX5r6UITYCHNb+UoXpfv0GSQUCjdtXpOdnR0d/fb3bRtGju4H7YwwCuJIYuKn69cvMxc0KFK/XqNGjZquXr0U0lgpKZ9PnDw6bvyQs2dPMWNr1qzt7l5m566tPj5VIPte7IciZMTwui3NsLez/3P7YStLq7HjBw8d3vvxkwczZ8yHVBSMatK4WS3/gPkLZ1z871/lC1mxfH2LFm2XLAvq0avt8f8datu2U69eX9KLLVu0g6x861YdVPlQhIwYJbcyuG3bNvgbGBhITMOJLbEJUbyBc3yI6dm96M2kdVUIMjrh4eFz5sw5fPgwMTqY2xKjxN0yY5MaQuyA9ySKiXvbwr7kEWIJvG5LTHztupo39yCE9AWv2xITV4j11N8WQkhdmNvKZ7J9yROEWAZzW/lM9fDFlB5iHcxtIYRYBnNb+bDUgRBLYG4rH+Z4EGIJzG2JUVjYQog9MLclJsLCFkLsgbkthBDLYG4LIcQymNsSMzPjcC1MNLtFcTCth1gG+9sSs3MyF5nkzT0f3vJpmgoLCyMIsQc+J1GseW9nPk/EN71Hoz69nmxtx12wYMGuXbsIQiyBua08larZBG+IGhBUiZiS9xHpY5dWHmZ18Pnz5/D2zJkznp6etWvXJggZMOxLPk/nUWX8GtodXf32+VXjL2amfxZdOpiw/6fI0Usrc6zEQ/z9/Zm/69evDw0NJQgZMLxu64sWvV1yc0XPbic9uvpRKBCqeymXSNxtl9x5qOIuC1M0QYHhooLXxIpEFKWwR9a8GUXyLqOFHDxNUdb23EFzvM2tCoyqWLHijh07UlJS4PX06dOHDRuGJS9kgPC6rQLa9HOFfwI+SU8RyBnNxABRgQGi/FcQQ0TyIpA4mBWcJfTFi0OHDy1etJgZS0Qys8jMX2jGL6Oo/BhZ6PMKTlBoaV9wiIMzhyjGFLSHDh165MgRCFuJiYkuLi4EIYOBuS05OObEwY1DtObVmQeVq5XR6keUXh0JeBETEzNt2rTly5dD2osgZADwui09gMoXYQ8IXrNmzXr9+jWErcePHwcEBBCE9Aqv29KDrKwswio1a9Zs3bo1vLh79+53332Xm5tLENIfvG5L196+fTtkyBDCToGBgStXroSwFRsbe/bsWYKQPmBuS9egttWsWTPCWt7e3vDX3d39+vXrL168mDp1KkFItygMT6jEkpOTnZyctm3b5ubm1rNnT4IMiRE/lRpzW7oG1aucnBxiFCBmwd+BAweGhoaGhIQQhHQCc1s6lZGRAQe5mZkZMSK2trZz58718/OD1506dTpz5gxBSJvkhy3IbfXr148gTYuMjOzatSsxRlyuOE8KVZJPnz4RSQ2FIKQdeE+iTvn7+8+cOZMYL9hzhg4dCi94PB60PEDOniCkaZjb0iloRkxLSyMmoEaNGhcvXmSu8Dp9+jRBSHMwt6VTI0aMMDc3J6bBwsKiVq1a8AKaIBo2bCgUCrHZGmkE5rZ0B9oQe/bsCQczMTG9evW6d+8eRVFv3rzZuHEjXmSPSglzW7pTvnz5GTPcKS4OAAAQAElEQVRmEFMFYcvX1xd2rTVr1hBJ8osgVCLY35buPHv2zNXVtVy5csSESW8j37x5MxS7pk2bxuEYdE8YyABhbkt35s+fLxAICJKYOnVqxYoVo6KiIOeVmJhIEFIZ3pOoI5mZmS1atMAuq2Qx+VPY0wYOHAi7HLRXEIRUgLktHbG2tsa7juWCnNe///5buXJlIukYJyYmhiCkFF63pSMPHjzAay+VaN68OfwtU6bMpEmTHj16RBBSDHNbOvLbb78ZzR3U2uPl5XXixAl3d3d4vW7dOrxDCMmF123pSJMmTfApOCoqX748/G3atOmSJUsICzuDRdqGuS0dCQwMJEgdjRs33r17N7x49+7dlClT4uPjCUISmNvShYcPH169epWgEvHz8+vTp89///1HJF1aE2Ty5IctoVCIVxhp0KVLl5h+XVDJNGvWbODAgfDiwoULM2fOxNuDVEHTNNM+a3zkH0tdu3bF67Y06KuvvqpYsSJBpTZq1Kg7d+4kJyebm5tzOBxbW1uCFAgLCyNGCnNbugDZZbzQVFMg5+Xm5mZmZgYn18uXLxOkALTDVqlShRgjzG3pwj///PP8+XOCNMfa2hpiFtSDiOSaOIKKgNKWaYUtvG5Ls+C4evPmDUGaxlyk+v79e8jZY5cShcAuZ6xhS/4Dx9LT02G4nZ0dQZoAYcvR0dFY86OGAFoYYXeFnRbSXsZ6rKolIyOjc+fOV65cIcZIfmkLMp0YszSofv36GLO0ysvLy9nZGfbbefPmnTp1ipg8Iy5qEUVh6+DBgwcOHCBIQyALc/fuXYK0zMLCAnKyFSpUIJKLTogJM8WwlZaWBvVEgjQE8vGhoaEE6UTdunXhL4fD+eabbzIzM4lJMu6whbktXYCwBW1eNWrUIEiHsrKy+Hw+/A0PD//666+JKRk9evSkSZMCAgKIMZJ/uSlexadZ/v7+BOmclYSNjc2KFSuioqIGDRpETAbmtlBpQWIL70nUFy6X++uvvzZt2hReHz9+PCUlhRi7+Ph4WwlipDC3pQuvX79++PAhQfrj7e0Nf318fHr16pWRkUGMmnEXtQjmtnQjLCwMDhVjTTSwDvwWnz9/vnXrVp8+fYgx2rlzJ7RFTJw4kRgpvG5LF3x9fTFmGQ7Idnl4eECRZPPmzcQYGX1pC3NbuvD06dOzZ88SZDAoivrxxx8HDBgAr3fs2PHy5UtiREw0bGFuS7PevXt3+/ZtggyMk5MT/G3duvWyZctSU1ONo485SO9EREQY910Z8i+AGDhwIPa3pUG1atVyc3MjyCBVqlRp3759PB4vISEhODh48uTJhM0gkQpJCWLU8LotLYJGq+zs7BwJOJPn5uby+XxLS8sbN24QZGAsLCwg4eXg4LBixYqgoCDCWkZfQySY29Kq5s2bwwk8OTkZatxZWVkQvKAM6+fnR5ChGjp06OzZs+HF2rVrmd7rZXXu3Bl+TWLYTDdsYW5LI0aMGOHl5SU7BNpne/fuTZABY7oeHDVqFLSiQJCCAjIzvFmzZvHx8cwz0AyZ6YYtyG0xjSyoNKDG0alTJ+YwYHh6enbp0oUggwe/3cqVKyFbApEL6ozdunWD+j78lPfv3z9y5AgxYKaQ28LrtrRr+PDh0odfQPakZ8+eBLGHmZlZmTJloKnx/fv3zBCo7O/duzcuLo4YpJSUFCgeGn37D+a2tAv2e0jMQ8CC1+XKlevevTtBbLNp0ybZhvXY2NiFCxcSg2QKNUSCuS0dgBo3NFFxuVyIWRDFCGKbmJgY2bdQVQwNDd25cycxPCYStgzlnsTLRz+GP03nZwsFucKCYygiEq8m80b8UnxBHUVRoi8TiAfD/yjJpAUoGCiep9DbQgNlRlOST8/7FEULUfFDZUcVXYLyscIiJ5nC0+StKiGKJ5N+hJL1Jwq+QlEUh6Y5lK0d99sxFR3LEAN3ZG3M5485ublCYeF9jBT9fYFQRNFUgW0l/REl27oAudtTuoTCFP1SBXZs2YUr+jnkrHZxsyj8dGUrzIwlFE1KOFZC4dpKcbi0uSXHu6Zt6/6uyhZkCJeV/nc4MfxpWuVa9tXqO4g4RLJaX/YLZoeQHQLvKWHhHUfufiN/oMJfTY68TyfFBT8is9r5o4rOpTxY5C9F/o9bzLywk4qKbCgVFiL/0woOVbRMmkPSEgXPb35KiMoetdTH3IoYrD/mRVnbcmo0cipb2VZY8Gp48bcj+aFIZteSfOkCXztvqyja/YpsykI7LTMWBgoLLvfLfHJ/4/xfVlOU7f+KAgszXPneI30tdyGU5MRLKZg3H03RL+8lhz9NrVjNpv1ghRk6+WELclswnHl8ubYdWRebmSLoPRUf2sxuB36K7DTCo2I1C2J4tgVFVm/oEtDGniCWCF4XY2Un6je9gtyxes5tJcaJEt/zMGYZAZ86Duf3vyeG5/CvsZa2XIxZ7NJ7qmfyh5yYMPnPvtTzPYk3TydY2XIJYr8mXZzDHn3OSidWBnZjWOoHfpW6jgSxjY292f1zSZ6+5YqO0vN1W5lpuWbmNEFGAZIw0a8N7kk5Ar7QxQMbcNmHYy7KSOfLHSW/pKOz3FZ2FrTrEGQccgUikSCXGJgcgWYz2khHcngiYY78Op/8sAW5LYKQmjA2IA2ClllKQU0M+9tCCBkikUjhZV567m+LoikKwyPSJsi40biPsZOispOe70kUCUVYrDMuBldThMSWEKuvLETTFK1WJRFzW6gERNI/CJWaUChS1F6HuS2kMfn36yGkARQFpS11WhJ1mNsimHcwGqK8G98NC8RRGs/BLAQlJ0WlLT3ntsS3lFJ4fjYStDj7TQyNCMuA7KT2BRA6y20pqb4i1hEJJXf5Gx4RRi02EilsSdRzbguiKV4AYTwkhWeCkCZQtKHmtuD8jGkHo4EtiUiDxFUxBY8Jx77kkcYYZkErv4NSxDKU4uu29NzfFkXhnWzGwzBjgySxZSg7WUTEm1ZtGjx9+oiwls6+gkioZkuizp6TqOS2I3ZZvOTHM/+cJKYNT0DFcnR0GjpktLt7WXgdGRnef2BXwgayqyr7FbRK7avkdZbbMhqvXoU2bPgVMW1YEyuWs7PLiOHjmNevXocSlpBdVdmvoFUikcI9St/Xbal/2VZyctKs2ZO6fNt8/IShZ/89vf3P34aN6MOMys3N/X3bhhGj+sLY2UHf3759nRkO5woo1r54GTJ/wQx40bd/5y1b1wvyn4OQlJS4bPlcOJn06NV2+Yr50dFvmeHBxw/1/q7D9RuX27RrtPG31cxyft3wC3xch05Nx44bfPLUMWZKWOb7+LhVq5d+270lMwRWbMKk4Z26NIO/x4IPqNIsq2jhAFYM3u7Zux3WpGu3FlCyS0z8xIy6fefG1Glj4YMGDemx4peFMPzduyhYnydPHjITXLh4Ft7+70Teg5SZsaEvnsPrkJCnsCW7dW81ZFivzVvWZWRkMNMsXDRrydIg2JIw5dVr/xGVGUdpi6kEwc7Tp2/H0YHiOofc/UrF7VxoL5LWsHbu2vrLysUJCfHw9uix/UTxfqjcxf/+HTykBywE9jTYCeEFrAkMP3R4D+wV0smYD7px4wrzVtH+mZaetmHTqkGDu3fu+g3sV3+fOQEDC61qoUoiLDNw7CDYaeGwmjNvKkzGDIe9FPaimzevduvRul2HJj9MHfNCstepQ2Hc0nNuSyRSuyVx5eol76KjVq3cvGzp2jt3bsA/6dPqN2xcCb9Bzx79Duw/3aJ5m4WLZ125epFInrEKf9esXdamTcdzZ2/NDVp25Oi+S5fPw0AIXlOnj3385MHUKXN2bD/s5Og8YeKw2Djxc/HMzc0zMzNOnToW9OOSnt37wpDfNq+5d+/WD9/P/nnFhs6de0CUgagBw8+eEf+dOWP+6ZOXiWQPhp+5qm+1A/tOjR41EVZp0+Y1xX4vRQtn1v/w4T3wNU/87+LuncHPnj/etft3GP467GXQnB/q1m24a8ex7yfPCg9//cvKRRUrVnJ3LxMS+pSZ9/nzx2XKlA3Nfwvz2trYVvOrERMbPWPWhGxe9qaNO5cuhsMpbOq0QDg+mY+LiHwD/5YvXVu7Vl2iFgMMXSL1rt1n9pY9+7b36ztk+rR5RMF+peJ2LroXMaDA0r/fUJjl0sX73/UZpGQ/VAKC4/Kf5sFeffLEfyNHjP9pxXwYyOUW08u5kv1z5crFoSFPp0wJgj2qenX/detXwLmt0KrKLur+gzsLFs1s377LkUNnFs7/OSHh/foNPzOjYDVg45y/cGbrlr3//H3dwtwCTqtEHUqCg55zW+pmS1NSPsO5ru93Q2pU93dxcYW9Kj4+77HmPB7v33N/DRwwvNu3vR3sHTp36t6mdcc9e/+QztuieduWLdrCTlmnTj2PcuVfv34BA589ewy//ZygpY0bNYXS7/hxU+wdHIODxSVNiqKys7P79x/Wtk1HT0/xQzrmz1+xatXmenUb1g1o0L1bH7+q1e/eu1l0Jc+cOVG7dt0pP/zo5OQME48YNu7EiSNQSFT+1ZQvvHz5CoMHjbSztYNv3bDBV8zKP3/22NLSEobDLgXrv2bVlgEDhsPwugENpWe2J08fduzwLfxl3sL3bdCgCUTACxf+MeOaQcCCw69SJZ8Z0+eHvXkFhQLmi8NWXbxwZdOmzSGRQVRmoE12au5klKT837BBEzhEq1erqWS/UmU7F92L5FKyHyoBKybJNI2xt7NvUL/xt116ERUo2T9h/Zs3bwPfHSJy4JjJv23a5eLipmRRO3Zuaf5N6z69Bzo4ONasWXvC+GlweL58lVejzMrMnDljARxrEMJgo0H5ETYmUZm4Vyu1WhJ11pe8uI1TnVpieEQY/PX3r8O8hfWsV68R8xqOZD6fD4e0dOKAOvWhQJuSmsK8rVq1unQUfL/0dPGdAHBWhEAGP17e+lAUzCXd+UA1v5pfPl4kOn780NDhvaGQDP/g5/lcJBgJhcLnIU9kVwNKQzDw6bPiWl6ULlx25e3s7DMyxGVh/1oBcEgEzZ0CRXcoPcGuAyEPhsPXYT4OonxUVES3b/tA5ZEpvcP3ZbZYSMiTatVqwizMMsuWLefh4SldSa+K3hAQiZoMtpJYglha1TdvgyvZr1TZzowCe5E8xe6Hcr1588rPrwaHw2He1pQcF8ozEsr3z1q1AqAiAikUqNzl5OTAuRN2DCVLg0I67EXSt35Va8Dfly9DmLcVKlaytrZmXsMRB3+hdE9URim+J0vPfcmre3NPWloq/LWx+dJiYG/vwLxgwtDkH0YVmiU5KZEpNtPymiVgLvh5IEzIDpQtYkAhP39VhT/O+SEnhz9m9KSAgAZQ8Cn6WQB2cVjgnzs2w78Cq6G0tFXswil5wR3K+VCjvHr14rY/NkJyqn69RsOHjYWYXr9+49TUFDh7Q0XPt4ofnL1r1Kj19OnDRo2axsXFNGrYlPniEBkLfXHYVnnf2qIkjzs0prv/pFtAyX6lynbOGfKQEAAAEABJREFUW1r+XqRIsfuhXJ8/J0MxXPrWyrL45+sq3z9nz1oE9dn/Lv0LwQsquT179oOinKJaJ+SRoPRkYfHl9MYEKagUM29pulR3qIoohQGYZf1tMdsoh//leR7Jn/PCgYuruDQ7fdpc2R8SQEttUtInRQuEOpeVldXyZetkB3JoTtEpIZEEp5HVqzbXzz+Lwq7m5upeaDIopMCP175dFyhsyw73KOdJFFNx4UVBnQL+QfbhwYM7wccPzpk75XjwefhS3t6VIbPwJvx1rdri5BSkqOAtzeFAiR1qlDDE2cUVTq2FmoQc7Ev7YC4D7AGilJTsV/BDF7udVf0UlfdDWVDu5vG/VLsysxQ+NkmQf7258v0TKpuQcxg0cMTz50+uXb+0d9+fUErq+91guctkyuPZ2VnSIRmSgOXi7Eo0QXwLjXH0t1Whghf8jYwKh3QMkcT7hw/vlikjLsd6lq9oITlDMhUlIjmBwLeAHylJcUGncuWqWVlZsAuW98gLK3HvYx0d5JzloCIAf6WhBCoF8M+7UmW5y4QWGelqwMnt/ftYSBYQxVRfuKzHjx/AXgthy9XVrUOHrmXLekyZFhif8N6zfAUo+UMjF5ThBw8WFxNq+Qds274RMu6QcMlbSR/fc+f/rlO7nvSUCJ+oJPmiCsnz6A2utFXKTpmV7FdEUsNSvp1VpPp+KAt+8Tt3b0BRnfkRnzx5IB1lZmYORSFYE6as9O5tpOxnyd0/odp78eJZSN5BPIJTGvyDSiicUBV9OiwZapGQs5cOYV77VPYlGqJob9Jzbktd8KN6eXnv3rMNGlkgZq3/dUW5cuWZUbAbQRUJcqWQ3YSSMLT1QEvZ+l9/Vr5AKN1AkX716qWQkoDYceLk0XHjh5w9e6rolJW8fOB3Onxkb2paKtQLNm5aBZlLiBFEXAa0cHNzv3//9qPH92FHGTNq0o0bl8/8cxL2J1gZaAaeNmMcn89XshpKFq4EJCkWLZ51+q/jUFmAtvbj/zsE8ausJIjXC4DD6YG4FOAfQMTZwIC3byOhRCZNuPTpMwhWD5qQIDsGuVJo4B85uh9UdkgpiPvbMryzXSk7ZVa+XxW7nZWAkwTkwq5fvwzbX/X9UFaLFm0/ffoI+QHY6yAXDjU76SiorkJsPfvvaSK5+uHAoV3SUYr2Ty6HC0fWoiWzoaiVlJR47tzfYW9eMt9LdlVlVwBaV6EZJzj4IOy3sPNv3rIW0nNQXyYaol4PEDrLbZXgERizZixYvXbZkKE9obzQrl1nyHNJW3OgmRbOJPALQREMhtesUXv69HnFLnDF8vWnTgcvWRYUGvoMSnNt23bq1at/0cmgzD93zjL4Xbv3aA31hblBSxOTPs1fMGPYiD67dx4bNHDkzl1boe3v4IG/4DS1bev+/Qd2QiyAIjSsxrKlay2UZouUL1zRXFB6h4C16bfVa9f9BNmT1q06rFu7jTm7wmEDUQ9aCaG1iEjOQ1A+hURy3fykL1QH/tx++NCh3WPHD4ZACYnVmTPmQ7KMlIKxXiWvZL8qdjsr0aRxMwgK8xfOGDY0cPiwQBX3Q1lwbhsb+P3p08GQH4BUFKzV4iU/MqOgDRSaI7dt27Bm7XIIYYGjJ0NJnKlCKdo/wZJFqzb+topJ5EH9d9zYKZ06diu0qtB0KF2B9u27fPz04fDRvXD+g324Qf0mkJwlmqOotEXJrQxu27YN/gYGBhIt2700ClLyfaZUUn0WOBdBAUGaOIB2NDhLLF2ymiB927X4TfsB7n4N7Ykh2TjtTfM+5Xxq2hBjB+ewnr3bLZi/olXLdoT9/rfpnShXOGxhpaKjDKC/LaIeOJ/Ex8eNHz8V0p9wdoICeaFEJkLICCjplNkA+ttSsz/MhQt/WbV6yR/bN338mOBV0Xvh/J8bqpn+1Jdvu7VUNGr27EXNvm5JWM4wK4k0m9s3DxzcdfDgLrmjvCr5bNqwgxg3BbuUnnNbHC5FCdSbxcHeYdmS4u+VMUAHDpxWNEqVK25QyUhOi2xNu/XuNeDbb3vLHVW0I1lHR6dLF+8TY0HRaoYtnV23Jcg1ob7k7WwNsXFWg4SG2mc7e68lYzLlxCQpeTSB/nNbhveoF1RCFD4XAGkQpWZpS5e5LXxyj9GgpH8QKjVK3ctNDbm/LWSw8BEYSIPEHdeoVUnU5T2JuJsbDQN9BIaS7uYQO+k5t2U0fcmjfAYXu0QEn97ISjRNEY5BPidR0tsWxi0jgZVEpEGG+5xEkVAkwpQ8Qkgdes5t4XMSEULq0nNui+bSlACrFUaC5tAG+FvSmIhgJzMzSmCY121Z25pnpuQSZBRoSlSmvDUxMFwzOi0lhyDWEdKWVvLjlp5zW74BtplpfILY79X9VA6HcvLgEgNja8+JfqGLp+chzUpPy6lcW353Q3p+TmKtZrZmlpxLhz4QxHJPryZXCTDEmy6/m1Dx83ssbbHM1WOfOFyqXlv5DzeQ300gxCwYrrN+mXctemtpbd5lbDmCWOjdq6wb/4tv0smldnPD6iBQKvG94Oi6tzUaO9Vtq8ZjH5G+nNkel5GaM3Kxl6IJKAN51MX+FdEpSXwOl87hFb5Ug7n7p9BqSm8Jkh0ud0oiThVTwvzEP8Vcf0iJJ2P+ysz/5aoj2VHS10XnKrQE2Q9irnGUnZIo7hu7wBpCikgoKvRli3596ZAC8xZcVcL0/iEqMrDwN6K+PF5PuhEkL2RXu+jsXDOYVdx9vE9Nu/ZDlT0HVO9iX/PP7I4V5IigFYifrX46teCvqepMzOZV82I2yTZX9cDM+wiaeT6XGp+jfIdUMIuaH0EToQhWS41rBTiWFMmh7B3NBs2toGzJctdDZ/1tFSAgDy6lZqYXeQCkBuIWLb1jWwSJY3F3GPkHpezEsH0pOQFJMpQ5XpkdUOF+CG1WQulckpVhNm9qalpISMhXTb8qvLbSiWla2oMPRdFFLmbL/8SiAUzSUiYUigqtqZwYI7vbyUY1kbDAQflleukmIoU/Pf8F14zj4mZVtZHBpeEViXvDj36dxuer2cebWIniltzdrPiZ1Iko+edhSXxUNwipe9sTrbArGUXrJpQ5plRgZW1Wt40Tp5gHrRnUcxI5pH5bqGUYaEWjNEJCPh797/is7t0I0iuPKuYeVVwIYjmWPSeRpaSPq0MIlZ6er9syETk5ORi2ENIUPV+3ZSKwtIWQBhlSbst4YdhCSIMwt6ULGLYQ0iDMbekChi2ENAhzW7oAKXkzMzOCENIEzG3pApa2ENIgzG3pAoYthDQIc1u6gGELIQ3C3JYuYG4LIQ3C3JYuYGkLIQ3C3JYuYNhCSIMwt6ULGLYQ0iDMbemCQCDAsIWQpmBuSxcgJW9jY0MQQpqAuS1dwEoiQhqEuS1dwLCFkAZhbksXMGwhpEGY29IFvNwUIQ3C3JYuYGkLIQ3C3JYuYNhCSIPk57auXr26atUqgjQkMzPT3d2dIIQ0QX7Yat68eXZ2dmpqKkGlNm7cuNatW9epU4cghDRB2dOxIXI9f/68fPny5cqVI0h9YWFhI0aMWL9+fYMGDQhCSEMo5al3Ho/Xp0+fP/74o2zZsgSp4/jx40ePHt21a5eFhQVBCGkOpUqL4atXrzw9PfH2FNUtXrzY3Nw8KCiIIIQ0jVZlIj8/P2gI69mzJ6SWCVIqLS0Nyqf16tXDmIWQllCqX58VHR195cqVwYMHE6TAzZs3586dCxVDLy8vghDSDqoEl5Vu2rRp0qRJBBX0+++/h4aG/vrrrwQhpE0qVRILgaLE6tWrCZIxceJEmqYxZiGkA1TJbuJJSEgoU6bMkydP8HKk8PDwkSNHrly5snHjxgQhpH0lvOMEYhb8vXfv3oMHD+CgJabq5MmTBw4cOHPmDDazIqQzJakkSo0ePdrFxYVIOh0mpmfZsmVPnz49fPgwxiyEdInSSE8PW7durV27dtOmTYlpyMzMHDFixIABA3r06EEQQrpVqtKW1Lhx4w4dOsTj8YgJuHPnTseOHX/66SeMWQjpBaXBfrX4fP7jx4/r16/P4XCIkdq+ffujR49+++03ghDSE82Uthjm5uZ+fn5ff/21sXaO+sMPP+Tm5mLMQki/KG30Yvr69WtoanRwcCDG4u3bt5DMghy86eTvEDJYmixtSVWtWhWi4fjx44lR+Ouvv6ZPn37ixAmMWQgZAkp7fcbfu3cvIiKiX79+hM1WrFgBTQ2LFi0iCCHDoJXSFqNhw4Z9+/aFF3v27JEOrFu3rsFenhoZGdm1a9dvvvmGeQvRauDAgZCtw5iFkEHRYtgCFEURyeO2du/eDS8gIkAjY1RU1KVLl4jhOXbs2Pv377Oysrp06XL//v3WrVtDwOrVqxdBCBkSSjcPFgsPD588efKHDx/gtVAorFOnzs6dO4khiYuLg2RcbGws8xZaRW/evEkQQoZHu6UtqZkzZzIxS/yRNA0FrqtXrxJDAkUtacwCUOYiCCGDpKOw9fbtW9m3KSkpBlXaSk5OvnLliuwQqMw2adKEIIQMjy7CVrdu3dzc3CDPBRVS5qZrKHDFxMRcu3aNGIbDhw9HR0czr6VraG9v37NnT4IQMjC6yG29vJd26/y7rFRKkEsRAefLB1KEpmiaQwkFX9ZBksQnzDTwGl5QNBEJCyyQpimhUHYWmEcknUvhwLwB5Msn5g+BdJt4SkooGSQkHL6dE6nxtWWTln4EIWRgtBu2jv4a+ymGByGGa8k1N+Oa2XA5HAoig5AUCDqwDjBURBSsCRO9mJeSyWiKEhZYbfEUhBSZXxKCCFV4MdLZmY+WTs6haViR3KxcXhafn50jzBVBxKzga91trAdBCBkMbYWtw2tjPsbwzK25bl5OTp5s7Y4qPuxzclyKIEdUqZp11zH4jFuEDILmw1Z8BP/4lhgzS65v0/LEKGQm8d8+eU/TZOzPPgQhpG8aDlsPL36+9U+iR1U3pwrG1uFnXEhiUlzq8AXeto5G2y0PQqygybAV8SzjzM54/3aViJHiZwpe34wescDbxkFHF44ghIrSWNi6fSb54aXkGq2N/7Gmz89HDl9Y2daBIgghfdBMqSEzVXT/QqIpxCxQ3r/M7iXhBCGkJ5oJW7uXRbpWNJ5OAZVzKmdtaWuxc1EUQQjpgwbC1t/b4+FvWT9nYjIqN/HISM0NvW2cfU8jZOA0ELYiQ9M9qroSE+Pgbnfz1CeCENK50oat8wc+0hzKobyBXu7w+NmFGfMbp2ckE02rUMeVxxNEv8aOIhDStdKGrchn6bbOJvpMZnNr85snscCFkK6VNmzl8AUmldWSZe9m/SnBJJ5oi5BB4ZJSeHoDctKUuZW2rhqPevf03KXt0TGhtjZO1f2atW812tJSXLK7cfvo+Ss7xo/csudQUMKHiHJlqjRvOqBhva7MXH+d3Xj/yRkLc+u6tTu4u1YkWlPG1+nj288EIaRbpSptvQvN4HC1db34p8To33dNzsnhTQrcPmzgL+8TwrbsGP9cegAAAASMSURBVC8Q5MIoDtcsKyvtxN+r+/aYs2rJ7dr+rY+cWJb8WdygefNu8M27x3p1mfnD2J0uTh7nL/1JtIkiVOitdIIQ0qFSBZ3sjFyOeanKa0o8fHKWyzEbPuCXMm6Vyrr7fNd9buz7V89f5PVBKhDktGs12qtCLYqiGgR0EYlEse9fw/Drt47UrtkGApm1tT2Uv6r4NCDaRNHUxzisJyKkU6UKWzyeUCQUEu2AGmIFzxo2No7MW2enci7OnpFvH0snqFi+JvPC2soe/mZlp0Hw+pQUXcbdWzqNp0c1ok00DbE7hyCEdKhUZSWKFolobfUymJWdHh0bOmN+Y9mBqWmJXz6dKnxXYDYvQygUWFhYS4eYm1sRbRKJ+0rF26oR0qlShS0LC266MJdoh52di7dXQIfWgbIDbWyU3UJkaWFD05ycnGzpEB4/k2iViLJx0FY1GSEkV6kOOQdXs4+x2srseJTxffDkjE+lujSdV5yJ/xDh5qKsZRDKX06O5aLePWvxdd6QF69uEG0SCoWelbVboEMIFVKqCo5ffQeBQFuVxOZNB0BQOPXPOj4/+8PHt3/9u2nNpoHvE94on6uOf9tnoZceP7sAr/+7tudtzHOiNdnpAqglVqyOYQshnSpV2KrgZ0FTVFqCVipi0BQ4Y9IBczOr9VuHrdzQNyLq4Xc95habYm/bYkTj+t1PnFkDSTEoanXrNIWIH96jldj6MSLZzBJ73UJI10rbTeCe5W/5fLpKE1N8ts2rK+8q+Fp1HlWWIIR0qLStYE3au/Ez+MT0CLKFuXwhxiyEdK+0rWBVG1pfPUHHhiSWr+kid4LPKQmrNw2UO8rKwjaLJ/8S87JuPpMC/yCaM295G0WjBIJcDkfOdqhUodbooesVzRX16L1jGXOCENI5DfQl//pBxvlD8TVbV5I7FoJCSuoHuaMg125ubil3FE1zHR3cieYkJccpGsXP4ZmbWRQdzuWY29vL70dMkENeXI6atLYyQQjpnGYegbH/l+isTFGVJkbyYMRivbz8zqe2dftBZQhCSOc0c4X3oNkVcnm5CWEpxAREPUiwtKUxZiGkLxq7MWXczz6f3iV/fJdBjFrE3fe8jOzh803iGUUIGSYNP5V688xw5/IOZf2ciDGKuBfPpXKHYsxCSK8ojV+KuWVWuJmlWZWvjCvPJSIvr74zt6BGLq5EEEJ6RWnjCvJDq2MS3/PsXGwq1nUj7Bd2+z0vLdvb367LSMxnIaR/lJZufIl+nXVuX0J2psDcysyxnJ2btz1hFZGAxIclpSZk8Hm5Ds7mQ+drsXNnhJBatBW2GHFhvGunPnz+lJvDF1JERJvRIiFF0wT+Kp+RgqnF/xU3GS2531CkytKE8PnFTMYRwoqJhCKREIi4ZnTZClbfjvbg4r3SCBkS7YYtKX4GeXztcyIUv1JzBXwiFAqUT09xKPF6CYtZNw6XhiAjKq4XCsnSxIGrmKVZcMy4tIU1p3xly9rfOBCEkEHSUdhCCCFNwZ45EUIsg2ELIcQyGLYQQiyDYQshxDIYthBCLINhCyHEMv8HAAD///IIjNoAAAAGSURBVAMAtcDaO8e9hzcAAAAASUVORK5CYII=",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001F0F4427AD0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d56d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: TEST THE AGENTIC RAG\n",
    "# ============================================================================\n",
    "def run_agentic_rag(question: str):\n",
    "    \"\"\"Run the agentic RAG system with a question\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"QUESTION: {question}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for chunk in graph.stream(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": question,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ):\n",
    "        for node, update in chunk.items():\n",
    "            print(f\"\\nUpdate from node: {node}\")\n",
    "            print(\"-\" * 40)\n",
    "            print(update[\"messages\"][-1])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8023989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUESTION: What are the main methods mentioned in this paper?\n",
      "============================================================\n",
      "\n",
      "Update from node: generate_query_or_respond\n",
      "----------------------------------------\n",
      "content='<think>\\nOkay, the user is asking about the main methods mentioned in a paper. But wait, the tools provided here are for retrieving documents from PDFs in a database. The function given is retrieve_documents, which takes a query parameter. However, the user\\'s question is about a paper\\'s methods, which implies they might be referring to a specific document they\\'ve uploaded or that\\'s in the database.\\n\\nWait, the problem is that the current tools don\\'t have a function that can extract methods from a paper. The retrieve_documents function is for searching and returning information from PDFs, but the user is asking for specific content (methods) which might require a different function, like extract_methods or something similar. But according to the tools provided, such a function isn\\'t available. \\n\\nHmm, maybe the user expects me to use the retrieve_documents function with a query about methods. So I should call retrieve_documents with the query \"main methods mentioned in this paper.\" But the function\\'s description says it searches and returns info from PDFs. If the database has the paper\\'s content, this function might retrieve the methods section. However, without knowing the exact content, I can\\'t be sure. But since that\\'s the only tool available, I have to use it. So the correct approach is to call retrieve_documents with the query parameter set to \"main methods mentioned in this paper.\"\\n</think>\\n\\n' additional_kwargs={} response_metadata={'model': 'qwen3', 'created_at': '2025-09-21T15:23:53.4762445Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2076122400, 'load_duration': 76439100, 'prompt_eval_count': 152, 'prompt_eval_duration': 162545300, 'eval_count': 304, 'eval_duration': 1835961300, 'model_name': 'qwen3'} id='run--a5d33a90-7b78-4baa-94b4-57e4473b103e-0' tool_calls=[{'type': 'tool_call', 'id': '98687a32-c858-4808-9ea1-b03444403015', 'name': 'retrieve_documents', 'args': {'query': 'main methods mentioned in this paper'}}] usage_metadata={'input_tokens': 152, 'output_tokens': 304, 'total_tokens': 456}\n",
      "\n",
      "🔍 Searching: 'main methods mentioned in this paper'\n",
      "✓ Found 4 relevant chunks\n",
      "\n",
      "Update from node: retrieve\n",
      "----------------------------------------\n",
      "content='Page 103: Method Non-football (DROP) Football (DROP) GSM8k\\nZero-Shot 43.86 51.77 16.38\\nStandard Prompting 58.78 62.73 17.06\\nChain-of-Thought 74.77 59.56 60.87\\nLeast-to-Most 82.45 73.42 62.39\\nTable 36: Accuracies of different prompting methods on GSM8k and DROP benchmarks. Source:\\nZhou et al. [244]\\nDECOMP is a text-based prompting strategy that decomposes complex tasks into simpler\\nsubtasks and generates a plan to solve the task, similar to Least-to-Most prompting. The\\ncore idea of Decomposed Prompting involves dividing a complex task into multiple simpler\\nsubtasks. Each subtask is addressed separately using LLMs, and their results are then combined\\nto produce the final outcome. Tasks are decomposed based on their inherent structure. For\\ninstance, a question-answering task might be split into subtasks involving information retrieval,\\ncomprehension, and synthesis. The model can process each step more effectively by focusing\\non these individual components.\\nFigure 48: The DECOMP framework. Source: Khot et al. [175]\\n\\nPage 4: the transformative impact of LLMs across various domains, including healthcare, finance,\\neducation, law, and scientific research.\\n• Section 3 focuses on the fundamental building blocks of LLMs, covering data preprocess-\\ning techniques, pre-training methodologies, and model adaptation strategies. It explores\\nvarious pre-training approaches, including unsupervised, supervised, and semi-supervised\\nlearning, emphasizing their impact on model performance and adaptability. The section\\nalso examines different data sources used in LLM training, categorizing them into gen-\\neral data like Web pages, books, and conversation text, specialized data such as scientific\\nliterature and code, and widely used datasets like Wikipedia, BookCorpus, and Com-\\nmonCrawl. It details the critical data preprocessing steps, such as quality filtering, data\\ncleaning, deduplication, and tokenization, and their role in preparing data for effective\\nLLM training. Moreover, it discusses model adaptation techniques like instruction tuning\\n\\nPage 95: Taylor need to do before this? A. get a certificate , B. teach\\nsmall children, C. work in a school\\nARC Science Choose your answer to the question: Which technology was\\ndeveloped most recently? A. cellular telephone, B. television,\\nC. refrigerator, D. airplane\\nQASC Science Choose your answer to the question: What is described in terms\\nof temperature and water in the air? A. storms; B. climate;\\nC. mass; D. seasonal; E. winter; F. density; G. length\\nHellaSWAG Event Choose your answer to the question: We see a chair with a pillow\\non it. A. a man holding a cat does curling. B. a man holding a\\ncat starts hitting objects on an item. C. a man holding a cat is\\nwrapping a box. D. a man holding a cat sits down on the\\nchair.\\nNumerSense Numerical a square is a shape with 〈mask〉equally length sides. (four)\\nProtoQA Prototypical Use simple words separated by commas to name something in\\nyour life that could cause you to lose weight. ( Eating less,\\nexercising more, stress.)\\n\\nPage 102: Figure 47: Least-to-most prompting teaches language models how to solve a complex problem by\\ndecomposing it to a series of simpler subproblems. It consists of two sequential stages: (1) decompo-\\nsition and (2) sequentially solving subproblems. The answer to the second subproblem is built on the\\nanswer to the first subproblem. The demonstration examples for each stage’s prompt are omitted in\\nthis illustration. Source: Zhou et al. [244]\\nLeast-to-most prompting also achieves 99.7% accuracy on the SCAN102 compositional gener-\\nalization benchmark with only 14 exemplars, compared to 16% with Chain-of-Thought prompt-\\ning. Table 35 shows the accuracy comparison. Least-to-most improves performance on GSM8k\\nand DROP benchmarks, particularly for problems requiring multiple solving steps. Table 36\\nshows the accuracy comparison.\\nMethod Code-davinci-002 Text-davinci-002 Code-davinci-001\\nStandard Prompting 16.7 6.0 0.4\\nChain-of-Thought 16.2 0.0 0.0\\nLeast-to-Most 99.7 76.0 60.7' name='retrieve_documents' id='76897c9f-39a1-4649-9d7f-3e51ae3e9364' tool_call_id='98687a32-c858-4808-9ea1-b03444403015'\n",
      "\n",
      "\n",
      "Update from node: generate_answer\n",
      "----------------------------------------\n",
      "content=\"<think>\\nOkay, let's tackle this question. The user is asking about the main methods mentioned in the paper. The context provided has several pages with different information.\\n\\nFirst, looking at Page 103, there's a table comparing different prompting methods: Zero-Shot, Standard Prompting, Chain-of-Thought, and Least-to-Most. These seem to be methods evaluated on benchmarks like GSM8k and DROP. Then, on Page 95, there are some example questions and answers, but they might not be the main methods. \\n\\nFurther down, Page 102 talks about Least-to-most prompting in detail, explaining its two stages: decomposition and solving subproblems. Also, there's mention of DECOMP as a text-based strategy that breaks tasks into subtasks. The context also references other methods like Chain-of-Thought and Standard Prompting from the table. \\n\\nThe user wants the main methods mentioned. From the context, the key methods are Zero-Shot, Standard Prompting, Chain-of-Thought, Least-to-Most, and DECOMP. However, the question is about the paper's main methods. The table on Page 103 lists these methods, and the DECOMP is explained in detail on Page 102. The answer should list these methods concisely. Need to make sure not to include other parts like the examples or the sections about LLMs. So, the main methods are Zero-Shot, Standard Prompt, Chain-of-Thought, Least-to-Most, and DECOMP. But wait, the user might be referring to the methods discussed in the paper, which includes the ones in the table and the DECOMP framework. So the answer should list these methods as the main ones mentioned.\\n</think>\\n\\nThe main methods mentioned in the paper include Zero-Shot, Standard Prompting, Chain-of-Thought, Least-to-Most, and Decomposed Prompting (DECOMP). These methods are evaluated on benchmarks like GSM8k and DROP, with Least-to-Most and DECOMP emphasizing task decomposition into subtasks for improved performance. The paper highlights their effectiveness in handling complex problem-solving scenarios.\" additional_kwargs={} response_metadata={'model': 'qwen3', 'created_at': '2025-09-21T15:24:03.5887184Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2901463000, 'load_duration': 158631900, 'prompt_eval_count': 1106, 'prompt_eval_duration': 118999700, 'eval_count': 437, 'eval_duration': 2623163300, 'model_name': 'qwen3'} id='run--9eb3fa01-b629-4c19-92ca-18892aef3370-0' usage_metadata={'input_tokens': 1106, 'output_tokens': 437, 'total_tokens': 1543}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the main methods mentioned in this paper?\"\n",
    "run_agentic_rag(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2b8e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUESTION: Tell me about earth\n",
      "============================================================\n",
      "\n",
      "Update from node: generate_query_or_respond\n",
      "----------------------------------------\n",
      "content='<think>\\nOkay, the user asked \"Tell me about earth.\" I need to figure out how to respond. Let me check the tools available. There\\'s a function called retrieve_documents that searches PDF documents in the database. The function requires a query parameter. Since the user is asking about Earth, I should use this function to get information from the documents. The query parameter should be \"Earth\" or \"about Earth.\" Let me call the function with \"Earth\" as the query. That should retrieve the relevant information from the PDFs. I\\'ll structure the tool call accordingly.\\n</think>\\n\\n' additional_kwargs={} response_metadata={'model': 'qwen3', 'created_at': '2025-09-21T15:24:04.5412232Z', 'done': True, 'done_reason': 'stop', 'total_duration': 938370100, 'load_duration': 118749500, 'prompt_eval_count': 146, 'prompt_eval_duration': 21908400, 'eval_count': 138, 'eval_duration': 796173900, 'model_name': 'qwen3'} id='run--cb87ed83-2bfb-47ca-b656-954b6806dfe5-0' tool_calls=[{'type': 'tool_call', 'id': '68f1825e-08ba-4b9d-b966-43b3e5b8db8d', 'name': 'retrieve_documents', 'args': {'query': 'Earth'}}] usage_metadata={'input_tokens': 146, 'output_tokens': 138, 'total_tokens': 284}\n",
      "\n",
      "🔍 Searching: 'Earth'\n",
      "✓ Found 4 relevant chunks\n",
      "\n",
      "Update from node: retrieve\n",
      "----------------------------------------\n",
      "content='Page 99: The environment is the world where the task is executed, which can be set up as the LLM\\nitself or an external system, e.g., a simulator or a virtual world like Minecraft [359, 337]. The\\nenvironment provides feedback to the task planner about the result of the actions, which can\\nbe used to update the plan, either in the form of natural language or from other multimodal\\nsignals [322, 301]\\n4.4.3 Plan generation\\nFor solving complex tasks, the planner needs to generate a long-term and multi-step plan, which\\nrequires the planner to be able to reason over long-term dependencies and develop a coherent\\nand consistent plan. First, it needs to understand the task and break it down into sub-tasks,\\nthen generate a plan that can accomplish the task by executing the sub-tasks in a proper order.\\nThe plan should be generated in an interpretable and executable way by the executor, which\\nacts according to the plan and interacts with the environment to accomplish the task. The\\n\\nPage 173: 2024-04-14.\\n[391] Common Crawl. https://commoncrawl.org/. Accessed: 2024-04-15.\\n[392] Project Gutenberg. https://www.gutenberg.org/. Accessed: 2024-04-14.\\n[393] Wikipedia. https://en.wikipedia.org/wiki/Main_Page. Accessed: 2024-04-14.\\n174\\n\\nPage 17: the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level\\naccuracy on a benchmark of physics, biology, and chemistry problems (GPQA).\\n20Claude 3.5 Sonnet and Gemini\\n21adversarial prompts that purposely try to circumvent model refusals for content it’s not supposed to produce\\n18\\n\\nPage 95: Taylor need to do before this? A. get a certificate , B. teach\\nsmall children, C. work in a school\\nARC Science Choose your answer to the question: Which technology was\\ndeveloped most recently? A. cellular telephone, B. television,\\nC. refrigerator, D. airplane\\nQASC Science Choose your answer to the question: What is described in terms\\nof temperature and water in the air? A. storms; B. climate;\\nC. mass; D. seasonal; E. winter; F. density; G. length\\nHellaSWAG Event Choose your answer to the question: We see a chair with a pillow\\non it. A. a man holding a cat does curling. B. a man holding a\\ncat starts hitting objects on an item. C. a man holding a cat is\\nwrapping a box. D. a man holding a cat sits down on the\\nchair.\\nNumerSense Numerical a square is a shape with 〈mask〉equally length sides. (four)\\nProtoQA Prototypical Use simple words separated by commas to name something in\\nyour life that could cause you to lose weight. ( Eating less,\\nexercising more, stress.)' name='retrieve_documents' id='ea4dacf7-304b-41a2-bec9-823b1188be5d' tool_call_id='68f1825e-08ba-4b9d-b966-43b3e5b8db8d'\n",
      "\n",
      "\n",
      "Update from node: rewrite_question\n",
      "----------------------------------------\n",
      "{'role': 'user', 'content': '<think>\\nOkay, the user asked \"Tell me about earth.\" I need to figure out what they really want. The word \"earth\" can mean different things. It could be the planet Earth, like the third rock from the sun, or it could refer to the soil, like the ground we walk on. Maybe they\\'re asking about the planet, but maybe they want information about the soil. \\n\\nWait, the original question is pretty vague. The user might not have specified which \"earth\" they\\'re interested in. So the improved question should clarify that. Let me think. If I ask \"Are you referring to the planet Earth or the soil (earth)?\", that would help narrow it down. But maybe there\\'s a better way. Alternatively, I could split it into two parts. For example, \"Could you clarify if you\\'re asking about the planet Earth or the soil (earth)?\" That way, the user can specify which one they want. \\n\\nAlternatively, maybe the user is asking about the Earth as a planet, but they might want more details. But since the original question is too broad, the improved version should ask for clarification. Let me check if there are other possible interpretations. Maybe \"earth\" could also refer to the element earth in the four elements, but that\\'s less likely. The main possibilities are planet Earth or soil. So the best approach is to ask the user to specify which one they mean. That way, the answer can be more accurate. So the improved question would be something like, \"Are you referring to the planet Earth or the soil (earth)?\" That should cover the main possibilities and ensure the user gets the information they need.\\n</think>\\n\\n**Improved Question:**  \\n\"Are you referring to the planet Earth or the soil (earth)?\"  \\n\\n**Reasoning:**  \\nThe original question is ambiguous because \"earth\" can refer to the planet, the ground/soil, or even the element. Clarifying the intent ensures the response addresses the user\\'s specific need, whether they want geological, astronomical, or environmental information.'}\n",
      "\n",
      "\n",
      "Update from node: generate_query_or_respond\n",
      "----------------------------------------\n",
      "content='<think>\\n</think>\\n\\n**Answer:**  \\nThe term \"earth\" can refer to two distinct concepts:  \\n\\n1. **Planet Earth**  \\n   - The third planet in our solar system, known for its diverse ecosystems, oceans, atmosphere, and unique conditions that support life.  \\n   - It is composed of layers including the crust (soil and rock), mantle, and core.  \\n\\n2. **Soil (Earth as ground)**  \\n   - The layer of mineral and organic material on the planet\\'s surface, formed by weathering of rocks and decomposition of organic matter.  \\n   - It is essential for plant growth and agriculture.  \\n\\nCould you clarify which concept you\\'re interested in? For example:  \\n- Are you asking about Earth as a planet (e.g., its geography, climate, or geology)?  \\n- Or are you referring to soil (e.g., its composition, role in ecosystems, or agricultural importance)?  \\n\\nThis will help provide a more accurate and detailed response! 🌍🌱' additional_kwargs={} response_metadata={'model': 'qwen3', 'created_at': '2025-09-21T15:24:13.1028177Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1460842000, 'load_duration': 112311600, 'prompt_eval_count': 1282, 'prompt_eval_duration': 138630600, 'eval_count': 205, 'eval_duration': 1206368000, 'model_name': 'qwen3'} id='run--5e052eab-43ea-4f86-806a-58d70ee9b17b-0' usage_metadata={'input_tokens': 1282, 'output_tokens': 205, 'total_tokens': 1487}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Tell me about earth\"\n",
    "run_agentic_rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1610de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
